{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/genaiconference/Agentic_KAG/blob/main/05_agentic_kag_inference_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic KAG\n"
      ],
      "metadata": {
        "id": "-PO9upJ5mkx6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "580fa1da"
      },
      "source": [
        "This notebook demonstrates the capabilities of Agentic KAG, a framework for building intelligent agents that can perform complex tasks and generate answers from Knoweldge Graphs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/genaiconference/Agentic_KAG.git"
      ],
      "metadata": {
        "id": "pVtZvT2aDWjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d181f3-a0e7-4191-b641-9943099644e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Agentic_KAG'...\n",
            "remote: Enumerating objects: 325, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 325 (delta 43), reused 30 (delta 30), pack-reused 268 (from 2)\u001b[K\n",
            "Receiving objects: 100% (325/325), 7.20 MiB | 11.84 MiB/s, done.\n",
            "Resolving deltas: 100% (166/166), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Packages"
      ],
      "metadata": {
        "id": "r-7IZdzFNWkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdIGyKHTmOuW",
        "outputId": "2abf8b99-1562-4127-d745-4c20c4584538"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/Agentic_KAG/requirements.txt --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pV6Xj-VQSuF",
        "outputId": "654bed68-4ce3-4272-838b-8407602013f4",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.8/442.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.23.4 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load credentials from .env"
      ],
      "metadata": {
        "id": "yVHjyNXsNevP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/Agentic_KAG/')\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()  # This loads .env at project root\n",
        "\n",
        "NEO4J_URI = os.getenv('AV_NEO4J_URL')\n",
        "NEO4J_USERNAME = os.getenv('AV_NEO4J_USERNAME')\n",
        "NEO4J_PASSWORD = os.getenv('AV_NEO4J_PASSWORD')\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Set OPENAI_API_KEY as env variable for openai/neo4j-graphrag compatibility\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "oU_Bak6ZNhKe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the Neo4j Driver\n",
        "The Neo4j driver allows you to connect and perform read and write transactions with the database."
      ],
      "metadata": {
        "id": "By3HKzenNuBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "driver = GraphDatabase.driver(\n",
        "    NEO4J_URI,\n",
        "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
        ")\n",
        "\n",
        "# (Optional) Test the connection\n",
        "driver.verify_connectivity()"
      ],
      "metadata": {
        "id": "QfQtxfS0NudH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize OpenAI LLM and Embeddings via neo4j-graphrag\n",
        "We will use OpenAI **GPT-4.1**. The GraphRAG Python package supports any LLM model, including models from OpenAI, Google VertexAI, Anthropic, Cohere, Azure OpenAI, local Ollama models, and any chat model that works with LangChain. You can also implement a custom interface for any other LLM.\n",
        "\n",
        "Likewise, we will use OpenAI’s **text-embedding-3-small** for the embedding model, but you can use other embedders from different providers."
      ],
      "metadata": {
        "id": "71ErZz2mNyiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j_graphrag.llm import OpenAILLM\n",
        "from neo4j_graphrag.embeddings import OpenAIEmbeddings\n",
        "\n",
        "llm = OpenAILLM(\n",
        "    model_name=\"gpt-4.1\",\n",
        "    model_params={\"temperature\": 0}\n",
        ")\n",
        "\n",
        "embedder = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\"\n",
        ")"
      ],
      "metadata": {
        "id": "b3eaWt8PN2D-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also initialize langchain llm to use for community detection & Summarization"
      ],
      "metadata": {
        "id": "wVWn66j1b6aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize OpenAI LLM using LangChain\n",
        "lang_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=\"gpt-4.1\", temperature=0)"
      ],
      "metadata": {
        "id": "MdXxKHAyb4M4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize OpenAI client"
      ],
      "metadata": {
        "id": "5ake60MVQmbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "open_ai_client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")"
      ],
      "metadata": {
        "id": "cT4jgHPlQsfN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Langfuse Handler for Tracing"
      ],
      "metadata": {
        "id": "sawR6ifuFJAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "from langfuse import get_client\n",
        "\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "# Verify connection\n",
        "if langfuse.auth_check():\n",
        "    print(\"Langfuse client is authenticated and ready!\")\n",
        "else:\n",
        "    print(\"Authentication failed. Please check your credentials and host.\")\n",
        "\n",
        "langfuse_handler = CallbackHandler()"
      ],
      "metadata": {
        "id": "PKXFS89tFKmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5ed7f4-3f0c-49d8-c691-140fc9d29303"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langfuse client is authenticated and ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define ReACT Agent"
      ],
      "metadata": {
        "id": "F5EONCpuHbjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    HumanMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    PromptTemplate,\n",
        ")\n",
        "import re\n",
        "import asyncio\n",
        "from typing import List, Union\n",
        "from langchain.agents import AgentOutputParser, AgentExecutor, create_react_agent\n",
        "from langchain.schema import AgentAction, AgentFinish\n",
        "\n",
        "\n",
        "\n",
        "# 1️⃣  ───── Robust multi-action parser ────────────────────────────\n",
        "class MultiActionOutputParser(AgentOutputParser):\n",
        "    \"\"\"\n",
        "    Extract *all* Action / Action Input pairs, even when inputs are\n",
        "    multi-line or there is text between blocks.\n",
        "    \"\"\"\n",
        "    _ACTION_RE = re.compile(\n",
        "        r\"\"\"Action\\s*\\d*:\\s*(.*?)\\s*\\n        # tool name\n",
        "            Action\\ Input\\s*\\d*:\\s*([\\s\\S]*?) # tool input (non-greedy)\n",
        "            (?=\\nAction|\\nObservation|\\nFinal|\\Z)  # stop at next block\n",
        "        \"\"\",\n",
        "        flags=re.IGNORECASE | re.VERBOSE,\n",
        "    )\n",
        "\n",
        "    def parse(self, text: str) -> Union[List[AgentAction], AgentFinish]:\n",
        "        # ---------- collect all tool calls ----------\n",
        "        matches = self._ACTION_RE.findall(text)\n",
        "        if matches:\n",
        "            return [\n",
        "                AgentAction(\n",
        "                    tool=tool.strip(),\n",
        "                    tool_input=tool_input.strip().strip('\"'),\n",
        "                    log=text,\n",
        "                )\n",
        "                for tool, tool_input in matches\n",
        "            ]\n",
        "\n",
        "        # ---------- or a final answer ----------\n",
        "        # final = re.search(r\"(?:Final Answer|Final Thought):\\s*(.*)\", text, flags=re.IGNORECASE | re.DOTALL)\n",
        "        final = re.search(r\"(?:Final Answer):\\s*(.*)\", text, flags=re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "        # final = re.search(r\"(?i)Final Answer:\\s*(?:\\*{2})?\\s*\\n+(.*)\", text, flags=re.IGNORECASE | re.DOTALL)   ###PushToQA 04-07-2025 fixed ** issue\n",
        "\n",
        "        if final:\n",
        "            return AgentFinish(\n",
        "                return_values={\"output\": final.group(1).strip()}, log=text\n",
        "            )\n",
        "\n",
        "        # ---------- fallback if no Action or Final Answer but appears like final output ----------\n",
        "        if text.strip():  # fallback: any non-empty text is assumed to be the final answer\n",
        "            return AgentFinish(\n",
        "                return_values={\"output\": text.strip()}, log=text\n",
        "            )\n",
        "\n",
        "        raise ValueError(f\"Could not parse agent output: {text!r}\")\n",
        "\n",
        "\n",
        "# 2️⃣  ───── Executor that really runs in parallel ────────────────\n",
        "class ParallelAgentExecutor(AgentExecutor):\n",
        "    async def _aiter_next_step(self, name_to_tool_map, inputs):\n",
        "        llm_output = await self.agent.aplan(\n",
        "            intermediate_steps=self.intermediate_steps, **inputs\n",
        "        )\n",
        "        parsed = self.output_parser.parse(llm_output)\n",
        "\n",
        "        # ----- run *all* Actions concurrently -----\n",
        "        if isinstance(parsed, list):\n",
        "            coros = [self._aperform_agent_action(name_to_tool_map, a) for a in parsed]\n",
        "            results = await asyncio.gather(*coros)\n",
        "\n",
        "            for a, r in zip(parsed, results):\n",
        "                self.intermediate_steps.append((a, r))\n",
        "                yield f\"Observation: {r}\\n\"\n",
        "\n",
        "        elif isinstance(parsed, AgentFinish):\n",
        "            self.intermediate_steps.append(\n",
        "                (parsed, parsed.return_values[\"output\"])\n",
        "            )\n",
        "            yield f\"Final Answer: {parsed.return_values['output']}\\n\"\n",
        "\n",
        "\n",
        "# 3️⃣  ───── Helper to build the agent + prompt ───────────────────\n",
        "def get_react_agent(llm, tools, system_prompt, verbose=False):\n",
        "    \"\"\"Helper function for creating agent executor\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"conversation_history\", optional=True),\n",
        "        HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
        "        AIMessagePromptTemplate(\n",
        "            prompt=PromptTemplate(input_variables=['agent_scratchpad'], template='{agent_scratchpad}')),\n",
        "    ])\n",
        "    agent = create_react_agent(llm, tools, prompt, output_parser=MultiActionOutputParser())\n",
        "\n",
        "    executor = ParallelAgentExecutor(agent=agent,\n",
        "                                     tools=tools,\n",
        "                                     verbose=verbose,\n",
        "                                     stream_runnable=True,\n",
        "                                     handle_parsing_errors=True,\n",
        "                                     max_iterations=20,\n",
        "                                     return_intermediate_steps=True,\n",
        "                                     )\n",
        "    return executor"
      ],
      "metadata": {
        "id": "wXhVyPhUHgsh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from neo4j_graphrag.schema import get_schema\n",
        "# get_schema(driver)"
      ],
      "metadata": {
        "id": "mEwyrJiB8Lk1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Tools\n",
        "\n",
        "Defining 4 tools used by the ReACT agent:\n",
        "\n",
        "- **Hybrid Retrieval tool**\n",
        "- **Hybrid Cypher Retrieval tool**\n",
        "- **Global Search tool**\n",
        "- **Local search tool**"
      ],
      "metadata": {
        "id": "uK81XaAQIN14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tools import av_hybrid_tool, av_hybrid_cypher_tool, global_retriever_tool, local_retriever_tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs1pzxdEFEoQ",
        "outputId": "6fca2171-f7c9-4ffc-d9e7-168827d98031"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 26 community summaries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6abb7364"
      },
      "source": [
        "## Agentic KAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "import json\n",
        "import prompts\n",
        "from schema import manual_schema\n",
        "\n",
        "def run_agentic_kag(query):\n",
        "    \"\"\"\n",
        "    Runs the answer using react agent and provided tools.\n",
        "    \"\"\"\n",
        "    # Run Hybrid Retrieval using all the available tools\n",
        "    hybrid_agent = get_react_agent(\n",
        "        lang_llm,\n",
        "        [av_hybrid_tool, av_hybrid_cypher_tool, global_retriever_tool, local_retriever_tool],\n",
        "        prompts.REACT_PROMPT,\n",
        "        verbose=True\n",
        "    )\n",
        "    hybrid_input = json.dumps({\n",
        "        \"query\": query,\n",
        "    })\n",
        "    answer = hybrid_agent.invoke({\"input\": hybrid_input,\n",
        "                                  \"SYSTEM_PROMPT\" : prompts.AV_SYSTEM_PROMPT,\n",
        "                                  }, config={\"callbacks\": [langfuse_handler]})\n",
        "    final_answer = answer['output']\n",
        "    return final_answer"
      ],
      "metadata": {
        "id": "KrCjyva5JwPq",
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "def get_ist_datetime():\n",
        "    \"\"\"Return current IST date and time as separate strings.\"\"\"\n",
        "    ist = pytz.timezone(\"Asia/Kolkata\")\n",
        "    now_ist = datetime.now(ist)\n",
        "\n",
        "    current_date = now_ist.strftime(\"%Y-%m-%d\")\n",
        "    current_time = now_ist.strftime(\"%H:%M\")\n",
        "\n",
        "    return current_date, current_time\n",
        "\n",
        "\n",
        "# Example usage\n",
        "def expand_question(question):\n",
        "    date_str, time_str = get_ist_datetime()\n",
        "    question = f\"{question} Current Date: {date_str} Current Time: {time_str}\"\n",
        "    return question"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kV4SKEEokQLJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's test some questions"
      ],
      "metadata": {
        "id": "-zKP4DSroCGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the main topics covered in the first half of Day 1.\"\n",
        "answer = run_agentic_kag(query)\n",
        "display(Markdown(answer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "collapsed": true,
        "id": "KO7SNyR469xK",
        "outputId": "75f2d9e9-f528-4a63-9308-61ef810f58e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ParallelAgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mQuestion: {\"query\": \"What are the main topics covered in the first half of Day 1.\"}\n",
            "\n",
            "Thought: To answer this, I need to identify all sessions and workshops scheduled for the first half of Day 1, then extract their main topics.\n",
            "Action: AVHybridCypher(query: \"List all sessions and workshops on Day 1 with their topics and start times. Filter for those in the first half of the day (morning to lunch).\")\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Question: {\"query\": \"What are the main topics covered in the first half of Day 1.\"}\n\nThought: To answer this, I need to identify all sessions and workshops scheduled for the first half of Day 1, then extract their main topics.\nAction: AVHybridCypher(query: \"List all sessions and workshops on Day 1 with their topics and start times. Filter for those in the first half of the day (morning to lunch).\")"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"List down all the sessions or workshops which uses LangGraph?\"\n",
        "answer = run_agentic_kag(query)\n",
        "display(Markdown(answer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vPbyhu496-_N",
        "outputId": "ac9949eb-fcc3-4f30-9073-9140c37d7c2a",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ParallelAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mQuestion: {\"query\": \"List down all the sessions or workshops which uses LangGraph?\"}\n",
            "\n",
            "Thought: This query requires structured search to identify all sessions or workshops that mention the use of LangGraph. I will use the AVHybridCypher tool to query the knowledge graph for this information.\n",
            "Action: AVHybridCypher\n",
            "Action Input: List all sessions and workshops where the technology or tool used includes 'LangGraph'.\u001b[0m\u001b[33;1m\u001b[1;3m- **Building Effective Agentic AI Systems: Lessons from the Field**\n",
            "  - Type: Hack Session\n",
            "  - Tools: LangGraph, FastMCP, LangMem, LangSmith\n",
            "\n",
            "- **AutoGen vs CrewAI vs LangGraph: Battle of the Agent Frameworks**\n",
            "  - Type: Hack Panel\n",
            "  - Tools: AutoGen, CrewAI, LangGraph\n",
            "\n",
            "- **Mastering Agentic Workflows with LangGraph**\n",
            "  - Type: Hack Session\n",
            "  - Tools: LangGraph\n",
            "\n",
            "- **Mastering Intelligent Agents: A Deep Dive into Agentic AI**\n",
            "  - Type: Workshop\n",
            "  - Tools: LangChain, LangGraph, CrewAI, FastAPI, LangFuse, Arize AI Phoenix, Tavily, WeatherAPI, Google Colab, Runpod.io, LangMem, Mem0\n",
            "\n",
            "- **LLMOps – Productionalizing Real-World Applications with LLMs and Agents**\n",
            "  - Type: Workshop\n",
            "  - Tools: Hugging Face, Qdrant, Amazon SageMaker, LangGraph, LangSmith, LangChain, AWS\n",
            "\n",
            "- **AgentOps: Building and Deploying AI Agents**\n",
            "  - Type: Workshop\n",
            "  - Tools: LangChain, LangGraph\n",
            "\n",
            "- **Building Intelligent Multimodal Agents: Integrating Vision, Speech & Language**\n",
            "  - Type: Workshop\n",
            "  - Tools: LangGraph, LangGraph Studio, SQLite, Qdrant, Groq LLMs, Whisper, ElevenLabs, Llama 3.2 Vision, Diffusion Models, Telegram Bot API, Telegram\n",
            "\n",
            "- **Agentic RAG Workshop: From Fundamentals to Real-World Implementations**\n",
            "  - Type: Workshop\n",
            "  - Tools: Google Colab notebooks, Azure Document Intelligence, Chroma Vector DB, LangChain, LangGraph, Langfuse, Travily web search, Neo4j\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n",
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mFinal Thought: I have identified all sessions and workshops at DHS 2025 that use LangGraph as a tool or technology, based on the structured knowledge graph search.\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "**Here are all the sessions and workshops at DHS 2025 that use LangGraph:**\n",
            "\n",
            "- **Building Effective Agentic AI Systems: Lessons from the Field**\n",
            "  - Type: Hack Session\n",
            "  - Tools: LangGraph, FastMCP, LangMem, LangSmith\n",
            "\n",
            "- **AutoGen vs CrewAI vs LangGraph: Battle of the Agent Frameworks**\n",
            "  - Type: Hack Panel\n",
            "  - Tools: AutoGen, CrewAI, LangGraph\n",
            "\n",
            "- **Mastering Agentic Workflows with LangGraph**\n",
            "  - Type: Hack Session\n",
            "  - Tools: LangGraph\n",
            "\n",
            "- **Mastering Intelligent Agents: A Deep Dive into Agentic AI**\n",
            "  - Type: Workshop\n",
            "  - Tools: LangChain, LangGraph, CrewAI, FastAPI, LangFuse, Arize AI Phoenix, Tavily, WeatherAPI, Google Colab, Runpod.io, LangMem, Mem0\n",
            "\n",
            "- **LLMOps – Productionalizing Real-World Applications with LLMs and Agents**\n",
            "  - Type: Workshop\n",
            "  - Tools: Hugging Face, Qdrant, Amazon SageMaker, LangGraph, LangSmith, LangChain, AWS\n",
            "\n",
            "- **AgentOps: Building and Deploying AI Agents**\n",
            "  - Type: Workshop\n",
            "  - Tools: LangChain, LangGraph\n",
            "\n",
            "- **Building Intelligent Multimodal Agents: Integrating Vision, Speech & Language**\n",
            "  - Type: Workshop\n",
            "  - Tools: LangGraph, LangGraph Studio, SQLite, Qdrant, Groq LLMs, Whisper, ElevenLabs, Llama 3.2 Vision, Diffusion Models, Telegram Bot API, Telegram\n",
            "\n",
            "- **Agentic RAG Workshop: From Fundamentals to Real-World Implementations**\n",
            "  - Type: Workshop\n",
            "  - Tools: Google Colab notebooks, Azure Document Intelligence, Chroma Vector DB, LangChain, LangGraph, Langfuse, Travily web search, Neo4j\n",
            "\n",
            "---\n",
            "\n",
            "If you found this helpful, do spread the word and recommend this app to your fellow attendees!  \n",
            "Try it out at [http://agentickag.dhs25.analyticsvidhya.com/](http://agentickag.dhs25.analyticsvidhya.com/) 🚀\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Here are all the sessions and workshops at DHS 2025 that use LangGraph:**\n\n- **Building Effective Agentic AI Systems: Lessons from the Field**\n  - Type: Hack Session\n  - Tools: LangGraph, FastMCP, LangMem, LangSmith\n\n- **AutoGen vs CrewAI vs LangGraph: Battle of the Agent Frameworks**\n  - Type: Hack Panel\n  - Tools: AutoGen, CrewAI, LangGraph\n\n- **Mastering Agentic Workflows with LangGraph**\n  - Type: Hack Session\n  - Tools: LangGraph\n\n- **Mastering Intelligent Agents: A Deep Dive into Agentic AI**\n  - Type: Workshop\n  - Tools: LangChain, LangGraph, CrewAI, FastAPI, LangFuse, Arize AI Phoenix, Tavily, WeatherAPI, Google Colab, Runpod.io, LangMem, Mem0\n\n- **LLMOps – Productionalizing Real-World Applications with LLMs and Agents**\n  - Type: Workshop\n  - Tools: Hugging Face, Qdrant, Amazon SageMaker, LangGraph, LangSmith, LangChain, AWS\n\n- **AgentOps: Building and Deploying AI Agents**\n  - Type: Workshop\n  - Tools: LangChain, LangGraph\n\n- **Building Intelligent Multimodal Agents: Integrating Vision, Speech & Language**\n  - Type: Workshop\n  - Tools: LangGraph, LangGraph Studio, SQLite, Qdrant, Groq LLMs, Whisper, ElevenLabs, Llama 3.2 Vision, Diffusion Models, Telegram Bot API, Telegram\n\n- **Agentic RAG Workshop: From Fundamentals to Real-World Implementations**\n  - Type: Workshop\n  - Tools: Google Colab notebooks, Azure Document Intelligence, Chroma Vector DB, LangChain, LangGraph, Langfuse, Travily web search, Neo4j\n\n---\n\nIf you found this helpful, do spread the word and recommend this app to your fellow attendees!  \nTry it out at [http://agentickag.dhs25.analyticsvidhya.com/](http://agentickag.dhs25.analyticsvidhya.com/) 🚀"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"List down all the sessions or workshops which uses Agentic RAG?\"\n",
        "answer = run_agentic_kag(query)\n",
        "display(Markdown(answer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "collapsed": true,
        "id": "vci0fojw3SA4",
        "outputId": "474a675a-70ed-4cc8-ad45-a1379e8626da"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ParallelAgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mQuestion: {\"query\": \"List down all the sessions or workshops which uses Agentic RAG?\"}\n",
            "\n",
            "Thought: To answer this, I need to search for all sessions and workshops that mention \"Agentic RAG\" as a topic, technology, or methodology. This requires structured graph search to identify relevant sessions/workshops based on their descriptions or tags.\n",
            "Action: AVHybridCypher(query: \"Find all sessions and workshops where the topic, description, or technology includes 'Agentic RAG'\")\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Question: {\"query\": \"List down all the sessions or workshops which uses Agentic RAG?\"}\n\nThought: To answer this, I need to search for all sessions and workshops that mention \"Agentic RAG\" as a topic, technology, or methodology. This requires structured graph search to identify relevant sessions/workshops based on their descriptions or tags.\nAction: AVHybridCypher(query: \"Find all sessions and workshops where the topic, description, or technology includes 'Agentic RAG'\")"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I am a big lover of ai agents and I am interested in putting things in production. Suggest me a tailor made agenda, mention the name of the Session or workshop along with Instructor name?\"\n",
        "answer = run_agentic_kag(query)\n",
        "display(Markdown(answer))"
      ],
      "metadata": {
        "id": "04TYb-9LE2Qr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "cb134193-aa53-4fab-d1e7-236e76d9a52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ParallelAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The question asks for a customized agenda focused on AI agents and production deployment, including session/workshop names and instructor names. I need to search for relevant workshops or sessions, ideally with a practical/production focus, and list their details.\n",
            "Action: GlobalRetrieval\n",
            "Action Input: AI agent workshops and sessions for production deployment with instructor names\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing communities in parallel: 100%|██████████| 26/26 [00:15<00:00,  1.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;1m\u001b[1;3m# AI Agent Workshops and Sessions for Production Deployment (with Instructor Names)\n",
            "\n",
            "A comprehensive review of the dataset reveals a rich set of workshops and sessions focused on the production deployment of AI agents, led by a diverse group of industry practitioners and experts. Below is a structured summary of the most relevant sessions, their focus areas, and the instructors involved.\n",
            "\n",
            "---\n",
            "\n",
            "## 1. End-to-End Agentic AI and LLMOps Workshops\n",
            "\n",
            "- **Kartik Nighania (Typewise)**  \n",
            "  Leads an end-to-end LLMOps workshop and hack session on engineering reliable agents at scale. Topics include RAG with Qdrant, SageMaker training/deployment, CI/CD, monitoring/logging, hallucination detection/guardrails, and memory systems.  \n",
            "  [Data: Entities (15, 29, 435, 466, 16), Relationships (633, 1299, 3)]\n",
            "\n",
            "- **Miguel Otero Pedrido (The Neural Maze)**  \n",
            "  Conducts a multimodal agents workshop and hack session focused on moving beyond proofs of concept, with emphasis on agent monitoring, evaluation, simulation, and multimodal integration (vision, speech, language).  \n",
            "  [Data: Entities (15, 29, 435, 466, 16), Relationships (633, 1299, 3)]\n",
            "\n",
            "---\n",
            "\n",
            "## 2. AG2 (AutoGen) and Multi-Agent System Workshops\n",
            "\n",
            "- **Hrushikesh Dokala (Atlan; fAIght Club), Dr. Qingyun Wu (AG2; Penn State), Chi Wang (AG2; FLAML)**  \n",
            "  Deliver a hands-on technical workshop on \"Mastering Real-World Agentic AI Applications with AG2 (AutoGen)\", covering production-grade agent design, integration, deployment, and application domains such as customer support, marketing, content, finance, and data analysis.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "---\n",
            "\n",
            "## 3. Hack Sessions on Production Deployment\n",
            "\n",
            "- **Bhaskarjit Sarmah (Domyn)**  \n",
            "  Leads a session on detecting and mitigating risks in agentic AI, demonstrating governance patterns including rate limits, PII scrubbing, role-based permissions, red-team prompts, alignment rubrics, and monitoring dashboards.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "- **Prakalp Somawanshi**  \n",
            "  Conducts a session on building a multi-modal generative AI assistant for energy infrastructure inspection, focusing on vision-language models, retrieval tools, and compliance.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "---\n",
            "\n",
            "## 4. Multi-Agent Frameworks and Workflow Workshops\n",
            "\n",
            "- **Praneeth Paikray (Manpower Group)**  \n",
            "  Co-leads a hands-on Hack Panel comparing AutoGen, CrewAI, and LangGraph for building a multi-agent Helpdesk AI Assistant, focusing on framework trade-offs and deployment.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "- **Sanathraj Narayan (Data Science Manager)**  \n",
            "  Leads a deep-dive LangGraph workshop on graph-based agentic workflows for enterprise multi-agent systems.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "---\n",
            "\n",
            "## 5. AgentOps, Agent Factory, and Observability\n",
            "\n",
            "- **Bhaskarjit Sarmah**  \n",
            "  Conducts a hands-on AgentOps workshop introducing operationalization of agentic AI and multi-agent practices.  \n",
            "  [Data: Bhaskarjit Sarmah workshop]\n",
            "\n",
            "- **Krishnakumar Menon**  \n",
            "  Outlines an Agent Factory approach for scaling production agents.  \n",
            "  [Data: Krishnakumar Menon session]\n",
            "\n",
            "- **Dipanjan Sarkar**  \n",
            "  Shares field lessons on architecting, optimizing, and observing agentic systems.  \n",
            "  [Data: Dipanjan Sarkar session]\n",
            "\n",
            "- **NVIDIA**  \n",
            "  Presents a vendor-led hack session on its Agent Intelligence toolkit for production environments.  \n",
            "  [Data: NVIDIA session]\n",
            "\n",
            "---\n",
            "\n",
            "## 6. Interoperability, Protocols, and No-Code Automation\n",
            "\n",
            "- **Nikhil Rana**  \n",
            "  Speaker for interoperability sessions pairing Anthropic's Model Context Protocol (MCP) with Google's Agent-to-Agent (A2A) protocol.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "- **Nitin Agarwal, Rutvik Acharya**  \n",
            "  Deliver the MCP session on standardized tool access for agents.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "---\n",
            "\n",
            "## 7. Robust, Scalable, and Multimodal Agent Systems\n",
            "\n",
            "- **Pranjal Singh**  \n",
            "  Leads a session on robust, scalable multi-agent systems for production deployment, emphasizing guardrails and multimodal grounding.  \n",
            "  [Data: Entities (1498, 1264, 992, 1666)]\n",
            "\n",
            "- **Anshu Kumar**  \n",
            "  Demonstrates a modular, fault-tolerant SEO content pipeline for production workflows.  \n",
            "  [Data: Entities (1498, 1264, 992, 1666)]\n",
            "\n",
            "- **Harshad Khadilkar**  \n",
            "  Focuses on discovery and novelty in LLM outputs for production agent deployment.  \n",
            "  [Data: Entities (1498, 1264, 992, 1666)]\n",
            "\n",
            "---\n",
            "\n",
            "## 8. Evaluation, Security, and Governance\n",
            "\n",
            "- **Ayush Thakur (Weights & Biases, Google Developer Expert)**  \n",
            "  Leads a session on end-to-end LLM evaluation for production deployment, including lifecycle design, CI/CD guardrails, and bias analysis.  \n",
            "  [Data: Entities (1285, 1286, 1287, 2544, 2541, +more); Relationships (1226, 3297, 3745, 3749, +more)]\n",
            "\n",
            "- **Dr. Kiran R, Satnam Singh, Shivaraj Mulimani (Acalvio)**  \n",
            "  Conduct sessions on GenAI model evaluation and operationalizing AI red teaming with industry tools and governance frameworks.  \n",
            "  [Data: Reports (1)]\n",
            "\n",
            "---\n",
            "\n",
            "## 9. Industry-Specific and Applied Sessions\n",
            "\n",
            "- **Pradeep Kumar (Emirates Airlines)**  \n",
            "  Hands-on session on building agentic AI systems for production, integrating computer vision and LLMs with safeguards.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "- **Deepak Sharma**  \n",
            "  Addresses reliability challenges in agentic AI systems, advocating for human-in-the-loop workflows and tools like Pydantic-AI.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "- **Vignesh Kumar**  \n",
            "  Demonstrates a serverless AI workflow on Google Cloud for automotive service video analysis at scale.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "- **Karan Sindwani (AWS)**  \n",
            "  Leads a session on scalable GenAI deployment, covering latency/throughput optimization and practical applications.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "---\n",
            "\n",
            "## 10. Additional Notable Sessions\n",
            "\n",
            "- **Ashish Tripathy (Pype AI), Mayank Aggarwal (evolvue AI/CreateHQ), Aashay Sachdeva (Sarvam AI)**  \n",
            "  Conduct a hack session on building a scalable healthcare Voice AI contact center for production deployment, covering real-time multimodal agents, telephony, autoscaling, and cost optimization.  \n",
            "  [Data: Main summary]\n",
            "\n",
            "- **Aashay Sachdeva, Vijay Gabale**  \n",
            "  Lead hack sessions on post-training alignment and fine-tuning of LLMs for real-world applications.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "- **Pavak Biswal (DGS), Abhilash Kulkarni (Dentsu), Arijit Mallick (DGS)**  \n",
            "  Present sessions on AI-first customer experience solutions, operationalizing production-ready agentic capabilities.  \n",
            "  [Data: Main data table]\n",
            "\n",
            "---\n",
            "\n",
            "## Summary Table\n",
            "\n",
            "| Instructor(s)                                   | Session Focus/Title                                                                                 |\n",
            "|-------------------------------------------------|-----------------------------------------------------------------------------------------------------|\n",
            "| Kartik Nighania                                 | LLMOps, reliable agent engineering, production deployment                                           |\n",
            "| Miguel Otero Pedrido                            | Multimodal agents, monitoring, evaluation, simulation                                               |\n",
            "| Hrushikesh Dokala, Dr. Qingyun Wu, Chi Wang     | AG2/AutoGen, production-grade agent design and deployment                                           |\n",
            "| Bhaskarjit Sarmah                               | AgentOps, risk mitigation, governance, operationalization                                           |\n",
            "| Prakalp Somawanshi                              | Multi-modal generative AI assistant for energy infrastructure                                       |\n",
            "| Praneeth Paikray, Sanathraj Narayan             | Multi-agent frameworks (AutoGen, CrewAI, LangGraph), enterprise deployment                          |\n",
            "| Krishnakumar Menon, Dipanjan Sarkar, NVIDIA     | Agent Factory, observability, Agent Intelligence toolkit                                            |\n",
            "| Nikhil Rana, Nitin Agarwal, Rutvik Acharya      | Interoperability, MCP, A2A protocols, no-code automation                                           |\n",
            "| Pranjal Singh, Anshu Kumar, Harshad Khadilkar   | Robust, scalable, multimodal agent systems, SEO pipelines, LLM output diversity                    |\n",
            "| Ayush Thakur                                    | LLM evaluation, CI/CD guardrails, bias analysis                                                     |\n",
            "| Dr. Kiran R, Satnam Singh, Shivaraj Mulimani    | GenAI evaluation, AI red teaming, governance                                                        |\n",
            "| Pradeep Kumar, Deepak Sharma                    | Agentic AI in aviation, reliability, human-in-the-loop                                              |\n",
            "| Vignesh Kumar                                   | Serverless AI workflow for automotive video analysis                                                |\n",
            "| Karan Sindwani                                  | Scalable GenAI deployment, latency/throughput optimization                                          |\n",
            "| Ashish Tripathy, Mayank Aggarwal, Aashay Sachdeva| Healthcare Voice AI contact center, real-time multimodal agents                                     |\n",
            "| Aashay Sachdeva, Vijay Gabale                   | Post-training alignment, fine-tuning LLMs                                                           |\n",
            "| Pavak Biswal, Abhilash Kulkarni, Arijit Mallick | AI-first customer experience, production-ready agentic capabilities                                 |\n",
            "\n",
            "---\n",
            "\n",
            "This summary highlights the breadth and depth of AI agent workshops and sessions available for production deployment, along with the names of the instructors leading these initiatives. For further details on specific sessions or additional instructors, please refer to the referenced data records.\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n",
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer.\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "**Tailor-Made Agenda for AI Agents in Production**\n",
            "\n",
            "---\n",
            "\n",
            "**1. End-to-End Agentic AI and LLMOps**\n",
            "- **Session:** Engineering Reliable Agents at Scale (LLMOps Workshop & Hack Session)\n",
            "- **Instructor:** Kartik Nighania (Typewise)\n",
            "\n",
            "---\n",
            "\n",
            "**2. Multimodal Agent Systems**\n",
            "- **Session:** Multimodal Agents: Beyond Proofs of Concept (Workshop & Hack Session)\n",
            "- **Instructor:** Miguel Otero Pedrido (The Neural Maze)\n",
            "\n",
            "---\n",
            "\n",
            "**3. Mastering Real-World Agentic AI Applications**\n",
            "- **Session:** Mastering Real-World Agentic AI Applications with AG2 (AutoGen)\n",
            "- **Instructors:** Hrushikesh Dokala (Atlan; fAIght Club), Dr. Qingyun Wu (AG2; Penn State), Chi Wang (AG2; FLAML)\n",
            "\n",
            "---\n",
            "\n",
            "**4. AgentOps and Risk Mitigation**\n",
            "- **Session:** Detecting and Mitigating Risks in Agentic AI\n",
            "- **Instructor:** Bhaskarjit Sarmah (Domyn)\n",
            "\n",
            "---\n",
            "\n",
            "**5. Multi-Agent Frameworks and Workflows**\n",
            "- **Session:** Building Multi-Agent Helpdesk AI Assistant (AutoGen, CrewAI, LangGraph Comparison)\n",
            "- **Instructors:** Praneeth Paikray (Manpower Group), Sanathraj Narayan (Data Science Manager)\n",
            "\n",
            "---\n",
            "\n",
            "**6. Agent Factory and Observability**\n",
            "- **Session:** Agent Factory for Scaling Production Agents\n",
            "- **Instructor:** Krishnakumar Menon\n",
            "\n",
            "- **Session:** Architecting, Optimizing, and Observing Agentic Systems\n",
            "- **Instructor:** Dipanjan Sarkar\n",
            "\n",
            "- **Session:** Agent Intelligence Toolkit for Production\n",
            "- **Instructor:** NVIDIA\n",
            "\n",
            "---\n",
            "\n",
            "**7. Interoperability and Protocols**\n",
            "- **Session:** Interoperability with MCP and A2A Protocols\n",
            "- **Instructors:** Nikhil Rana, Nitin Agarwal, Rutvik Acharya\n",
            "\n",
            "---\n",
            "\n",
            "**8. Robust, Scalable, and Multimodal Agent Systems**\n",
            "- **Session:** Robust, Scalable Multi-Agent Systems for Production\n",
            "- **Instructor:** Pranjal Singh\n",
            "\n",
            "- **Session:** Modular, Fault-Tolerant SEO Content Pipeline\n",
            "- **Instructor:** Anshu Kumar\n",
            "\n",
            "- **Session:** Discovery and Novelty in LLM Outputs\n",
            "- **Instructor:** Harshad Khadilkar\n",
            "\n",
            "---\n",
            "\n",
            "**9. Evaluation, Security, and Governance**\n",
            "- **Session:** End-to-End LLM Evaluation for Production Deployment\n",
            "- **Instructor:** Ayush Thakur (Weights & Biases, Google Developer Expert)\n",
            "\n",
            "- **Session:** GenAI Model Evaluation and AI Red Teaming\n",
            "- **Instructors:** Dr. Kiran R, Satnam Singh, Shivaraj Mulimani (Acalvio)\n",
            "\n",
            "---\n",
            "\n",
            "**10. Industry-Specific and Applied Sessions**\n",
            "- **Session:** Building Agentic AI Systems for Aviation\n",
            "- **Instructor:** Pradeep Kumar (Emirates Airlines)\n",
            "\n",
            "- **Session:** Reliability in Agentic AI Systems (Human-in-the-Loop, Pydantic-AI)\n",
            "- **Instructor:** Deepak Sharma\n",
            "\n",
            "- **Session:** Serverless AI Workflow for Automotive Video Analysis\n",
            "- **Instructor:** Vignesh Kumar\n",
            "\n",
            "- **Session:** Scalable GenAI Deployment\n",
            "- **Instructor:** Karan Sindwani (AWS)\n",
            "\n",
            "---\n",
            "\n",
            "**11. Healthcare and Customer Experience**\n",
            "- **Session:** Scalable Healthcare Voice AI Contact Center\n",
            "- **Instructors:** Ashish Tripathy (Pype AI), Mayank Aggarwal (evolvue AI/CreateHQ), Aashay Sachdeva (Sarvam AI)\n",
            "\n",
            "- **Session:** Post-Training Alignment and Fine-Tuning of LLMs\n",
            "- **Instructors:** Aashay Sachdeva, Vijay Gabale\n",
            "\n",
            "- **Session:** AI-First Customer Experience Solutions\n",
            "- **Instructors:** Pavak Biswal (DGS), Abhilash Kulkarni (Dentsu), Arijit Mallick (DGS)\n",
            "\n",
            "---\n",
            "\n",
            "**This agenda covers the full spectrum from agent design, deployment, monitoring, and evaluation to industry-specific applications, led by top practitioners and experts in the field** [source](#ai-agent-workshops-and-sessions-for-production-deployment-with-instructor-names).\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Tailor-Made Agenda for AI Agents in Production**\n\n---\n\n**1. End-to-End Agentic AI and LLMOps**\n- **Session:** Engineering Reliable Agents at Scale (LLMOps Workshop & Hack Session)\n- **Instructor:** Kartik Nighania (Typewise)\n\n---\n\n**2. Multimodal Agent Systems**\n- **Session:** Multimodal Agents: Beyond Proofs of Concept (Workshop & Hack Session)\n- **Instructor:** Miguel Otero Pedrido (The Neural Maze)\n\n---\n\n**3. Mastering Real-World Agentic AI Applications**\n- **Session:** Mastering Real-World Agentic AI Applications with AG2 (AutoGen)\n- **Instructors:** Hrushikesh Dokala (Atlan; fAIght Club), Dr. Qingyun Wu (AG2; Penn State), Chi Wang (AG2; FLAML)\n\n---\n\n**4. AgentOps and Risk Mitigation**\n- **Session:** Detecting and Mitigating Risks in Agentic AI\n- **Instructor:** Bhaskarjit Sarmah (Domyn)\n\n---\n\n**5. Multi-Agent Frameworks and Workflows**\n- **Session:** Building Multi-Agent Helpdesk AI Assistant (AutoGen, CrewAI, LangGraph Comparison)\n- **Instructors:** Praneeth Paikray (Manpower Group), Sanathraj Narayan (Data Science Manager)\n\n---\n\n**6. Agent Factory and Observability**\n- **Session:** Agent Factory for Scaling Production Agents\n- **Instructor:** Krishnakumar Menon\n\n- **Session:** Architecting, Optimizing, and Observing Agentic Systems\n- **Instructor:** Dipanjan Sarkar\n\n- **Session:** Agent Intelligence Toolkit for Production\n- **Instructor:** NVIDIA\n\n---\n\n**7. Interoperability and Protocols**\n- **Session:** Interoperability with MCP and A2A Protocols\n- **Instructors:** Nikhil Rana, Nitin Agarwal, Rutvik Acharya\n\n---\n\n**8. Robust, Scalable, and Multimodal Agent Systems**\n- **Session:** Robust, Scalable Multi-Agent Systems for Production\n- **Instructor:** Pranjal Singh\n\n- **Session:** Modular, Fault-Tolerant SEO Content Pipeline\n- **Instructor:** Anshu Kumar\n\n- **Session:** Discovery and Novelty in LLM Outputs\n- **Instructor:** Harshad Khadilkar\n\n---\n\n**9. Evaluation, Security, and Governance**\n- **Session:** End-to-End LLM Evaluation for Production Deployment\n- **Instructor:** Ayush Thakur (Weights & Biases, Google Developer Expert)\n\n- **Session:** GenAI Model Evaluation and AI Red Teaming\n- **Instructors:** Dr. Kiran R, Satnam Singh, Shivaraj Mulimani (Acalvio)\n\n---\n\n**10. Industry-Specific and Applied Sessions**\n- **Session:** Building Agentic AI Systems for Aviation\n- **Instructor:** Pradeep Kumar (Emirates Airlines)\n\n- **Session:** Reliability in Agentic AI Systems (Human-in-the-Loop, Pydantic-AI)\n- **Instructor:** Deepak Sharma\n\n- **Session:** Serverless AI Workflow for Automotive Video Analysis\n- **Instructor:** Vignesh Kumar\n\n- **Session:** Scalable GenAI Deployment\n- **Instructor:** Karan Sindwani (AWS)\n\n---\n\n**11. Healthcare and Customer Experience**\n- **Session:** Scalable Healthcare Voice AI Contact Center\n- **Instructors:** Ashish Tripathy (Pype AI), Mayank Aggarwal (evolvue AI/CreateHQ), Aashay Sachdeva (Sarvam AI)\n\n- **Session:** Post-Training Alignment and Fine-Tuning of LLMs\n- **Instructors:** Aashay Sachdeva, Vijay Gabale\n\n- **Session:** AI-First Customer Experience Solutions\n- **Instructors:** Pavak Biswal (DGS), Abhilash Kulkarni (Dentsu), Arijit Mallick (DGS)\n\n---\n\n**This agenda covers the full spectrum from agent design, deployment, monitoring, and evaluation to industry-specific applications, led by top practitioners and experts in the field** [source](#ai-agent-workshops-and-sessions-for-production-deployment-with-instructor-names)."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I am a big lover of knowledge graphs (do not confuse with LangGraph). Suggest me a tailor made agenda, mention the name of the Session or workshop along with Instructor name and whn it is happening?\"\n",
        "answer = run_agentic_kag(query)\n",
        "display(Markdown(answer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m5m4flGyv0ng",
        "outputId": "0f3b1ae7-1410-4cdf-d17b-24b08d26bfdc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ParallelAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The question is about knowledge graphs (not LangGraph) and requests a tailored agenda with session/workshop names, instructor names, and timings. I need to search for relevant sessions or workshops about knowledge graphs, including their details.\n",
            "Action: GlobalRetrieval\n",
            "Action Input: knowledge graph sessions or workshops, instructor names, and schedule\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing communities in parallel: 100%|██████████| 26/26 [00:14<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;1m\u001b[1;3m# Knowledge Graph Sessions or Workshops: Instructors and Schedule\n",
            "\n",
            "## Overview\n",
            "\n",
            "The dataset contains information on several sessions and workshops relevant to knowledge graphs and their applications, though not all are explicitly titled as \"knowledge graph\" sessions. Below is a synthesis of the available details, including session topics, instructor names, and scheduling information where provided.\n",
            "\n",
            "---\n",
            "\n",
            "## Explicit Knowledge Graph Session\n",
            "\n",
            "- **Session Title:** The Missing Piece of AI Apps: Evaluation  \n",
            "  **Type:** Day 2 Hack Session  \n",
            "  **Date & Time:** 2025-08-21, 16:00–17:00  \n",
            "  **Instructor:** Ayush Thakur (Manager, AI Engineer at Weights & Biases; Google Developer Expert in Machine Learning)  \n",
            "  [Data: Entities (1285, 1286, 1287); Relationships (1226, 3297)]\n",
            "\n",
            "---\n",
            "\n",
            "## Related Workshops and Hack Sessions\n",
            "\n",
            "### 1. LangGraph Workshop\n",
            "- **Focus:** Graph-based agentic workflows, agent architectures with memory/tools, reflexion and error-handling loops, retrieval+reasoning, and experiment tracking.\n",
            "- **Instructor:** Sanathraj Narayan (Data Science Manager)\n",
            "- **Schedule:** Day 3 (exact time not specified)\n",
            "- [Data: Reports (content references LangGraph workshop and Day 3 schedule)]\n",
            "\n",
            "### 2. Knowledge Graph-Related Hack Sessions\n",
            "- **Session 1:** Measuring Uncertainty in LLMs and Optimal Use of SLMs  \n",
            "  **Instructor:** Kuldeep Jiwani (ConcertAI)\n",
            "- **Session 2:** Fast and Accurate Conversational Agents: Beyond Function Calling  \n",
            "  **Instructor:** Daksh Varshneya (Rasa)\n",
            "- **Schedule:** Not specified\n",
            "- [Data: Reports (+more)]\n",
            "\n",
            "### 3. GenAI Model Evaluation and AI Red Teaming\n",
            "- **Day 2 PowerTalk:** Evaluating GenAI models (technical, observability, business)  \n",
            "  **Instructor:** Dr. Kiran R\n",
            "- **Day 3 Hack Session:** Operationalizing AI red teaming  \n",
            "  **Instructors:** Satnam Singh and Shivaraj Mulimani (Acalvio)\n",
            "- **Schedule:** Day 2 (PowerTalk), Day 3 (Hack Session)\n",
            "- [Data: Reports (session descriptions)]\n",
            "\n",
            "### 4. From Idea to Production with GenAI\n",
            "- **Type:** Day 2 Hack Session  \n",
            "- **Focus:** GenAI production practices (relevant to knowledge graphs)\n",
            "- **Instructor:** Karan Sindwani (AWS Senior Applied Scientist)\n",
            "- **Schedule:** Day 2\n",
            "- [Data: Reports (summary)]\n",
            "\n",
            "---\n",
            "\n",
            "## Additional Sessions with Knowledge Graph Relevance\n",
            "\n",
            "- **Workshop:** Mastering Real-World Agentic AI Applications with AG2 (AutoGen)  \n",
            "  **Instructors:** Hrushikesh Dokala (Atlan; fAIght Club), Dr. Qingyun Wu (AG2; Penn State), Chi Wang (AG2; FLAML)  \n",
            "  **Schedule:** Not specified  \n",
            "  [Data: Reports (curriculum description)]\n",
            "\n",
            "- **Hack Sessions:**  \n",
            "  - Post-Training Is Back: From Prompts to Policies (Aashay Sachdeva)  \n",
            "  - Why GenAI and LLMs Fail and How Fine-Tuning Helps Them (Vijay Gabale)  \n",
            "  **Schedule:** Not specified  \n",
            "  [Data: Reports (no explicit report ids provided)]\n",
            "\n",
            "---\n",
            "\n",
            "## Sessions with Partial or No Schedule Information\n",
            "\n",
            "Many sessions and workshops relevant to knowledge graphs, agentic AI, and GenAI evaluation are listed without specific dates or times. Where possible, day-level scheduling (e.g., \"Day 2\" or \"Day 3\") is provided, but exact times are often missing.\n",
            "\n",
            "---\n",
            "\n",
            "## Summary Table\n",
            "\n",
            "| Session Title / Topic                                      | Instructor(s)                                   | Date / Schedule           |\n",
            "|------------------------------------------------------------|-------------------------------------------------|---------------------------|\n",
            "| The Missing Piece of AI Apps: Evaluation                   | Ayush Thakur                                    | 2025-08-21, 16:00–17:00   |\n",
            "| LangGraph Workshop                                         | Sanathraj Narayan                               | Day 3                     |\n",
            "| Measuring Uncertainty in LLMs and Optimal Use of SLMs      | Kuldeep Jiwani                                  | Not specified             |\n",
            "| Fast and Accurate Conversational Agents                    | Daksh Varshneya                                 | Not specified             |\n",
            "| Evaluating GenAI Models (PowerTalk)                        | Dr. Kiran R                                     | Day 2                     |\n",
            "| Operationalizing AI Red Teaming (Hack Session)             | Satnam Singh, Shivaraj Mulimani                 | Day 3                     |\n",
            "| From Idea to Production with GenAI                         | Karan Sindwani                                  | Day 2                     |\n",
            "| Mastering Real-World Agentic AI Applications with AG2      | Hrushikesh Dokala, Dr. Qingyun Wu, Chi Wang     | Not specified             |\n",
            "| Post-Training Is Back: From Prompts to Policies            | Aashay Sachdeva                                 | Not specified             |\n",
            "| Why GenAI and LLMs Fail and How Fine-Tuning Helps Them     | Vijay Gabale                                    | Not specified             |\n",
            "\n",
            "---\n",
            "\n",
            "## Key Implications\n",
            "\n",
            "- **Instructor Diversity:** Sessions are led by a mix of industry practitioners, researchers, and product leads from organizations such as Weights & Biases, AWS, ConcertAI, Rasa, Atlan, Penn State, FLAML, and Acalvio.\n",
            "- **Schedule Availability:** Only a few sessions have precise date and time information; most are identified by day or lack specific scheduling.\n",
            "- **Knowledge Graph Focus:** While only one session is explicitly titled as a knowledge graph session, several others cover adjacent topics such as agentic workflows, GenAI evaluation, and conversational agents, which are highly relevant to knowledge graph applications.\n",
            "\n",
            "If you need more details on a specific session or instructor, please specify.\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n",
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer.\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "**Tailor-Made Agenda for Knowledge Graph Enthusiasts**\n",
            "\n",
            "---\n",
            "\n",
            "**1. The Missing Piece of AI Apps: Evaluation**\n",
            "- **Instructor:** Ayush Thakur (Manager, AI Engineer at Weights & Biases; Google Developer Expert in Machine Learning)\n",
            "- **When:** 2025-08-21, 16:00–17:00\n",
            "- **Type:** Day 2 Hack Session\n",
            "- **Why Attend:** This session is explicitly focused on evaluation in AI apps, a crucial aspect of knowledge graph applications and their integration in AI systems.  \n",
            "  [Source](#)\n",
            "\n",
            "---\n",
            "\n",
            "**2. Measuring Uncertainty in LLMs and Optimal Use of SLMs**\n",
            "- **Instructor:** Kuldeep Jiwani (ConcertAI)\n",
            "- **When:** Schedule not specified\n",
            "- **Why Attend:** This session covers uncertainty in language models, which is highly relevant for knowledge graph-based reasoning and applications.  \n",
            "  [Source](#)\n",
            "\n",
            "---\n",
            "\n",
            "**3. Fast and Accurate Conversational Agents: Beyond Function Calling**\n",
            "- **Instructor:** Daksh Varshneya (Rasa)\n",
            "- **When:** Schedule not specified\n",
            "- **Why Attend:** Conversational agents often leverage knowledge graphs for context and reasoning, making this session valuable for practical applications.  \n",
            "  [Source](#)\n",
            "\n",
            "---\n",
            "\n",
            "**4. From Idea to Production with GenAI**\n",
            "- **Instructor:** Karan Sindwani (AWS Senior Applied Scientist)\n",
            "- **When:** Day 2\n",
            "- **Why Attend:** Focuses on productionizing GenAI, which often involves knowledge graph integration for real-world deployments.  \n",
            "  [Source](#)\n",
            "\n",
            "---\n",
            "\n",
            "**5. Mastering Real-World Agentic AI Applications with AG2 (AutoGen)**\n",
            "- **Instructors:** Hrushikesh Dokala (Atlan; fAIght Club), Dr. Qingyun Wu (AG2; Penn State), Chi Wang (AG2; FLAML)\n",
            "- **When:** Schedule not specified\n",
            "- **Why Attend:** This workshop covers agentic AI applications, which frequently utilize knowledge graphs for memory and reasoning.  \n",
            "  [Source](#)\n",
            "\n",
            "---\n",
            "\n",
            "**Summary Table**\n",
            "\n",
            "| Session Title / Topic                                      | Instructor(s)                                   | Date / Schedule           |\n",
            "|------------------------------------------------------------|-------------------------------------------------|---------------------------|\n",
            "| The Missing Piece of AI Apps: Evaluation                   | Ayush Thakur                                    | 2025-08-21, 16:00–17:00   |\n",
            "| Measuring Uncertainty in LLMs and Optimal Use of SLMs      | Kuldeep Jiwani                                  | Not specified             |\n",
            "| Fast and Accurate Conversational Agents                    | Daksh Varshneya                                 | Not specified             |\n",
            "| From Idea to Production with GenAI                         | Karan Sindwani                                  | Day 2                     |\n",
            "| Mastering Real-World Agentic AI Applications with AG2      | Hrushikesh Dokala, Dr. Qingyun Wu, Chi Wang     | Not specified             |\n",
            "\n",
            "---\n",
            "\n",
            "**Note:** Only the first session has a precise date and time. For the others, please check the event’s official schedule for updates.  \n",
            "[Source: GlobalRetrieval results]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Tailor-Made Agenda for Knowledge Graph Enthusiasts**\n\n---\n\n**1. The Missing Piece of AI Apps: Evaluation**\n- **Instructor:** Ayush Thakur (Manager, AI Engineer at Weights & Biases; Google Developer Expert in Machine Learning)\n- **When:** 2025-08-21, 16:00–17:00\n- **Type:** Day 2 Hack Session\n- **Why Attend:** This session is explicitly focused on evaluation in AI apps, a crucial aspect of knowledge graph applications and their integration in AI systems.  \n  [Source](#)\n\n---\n\n**2. Measuring Uncertainty in LLMs and Optimal Use of SLMs**\n- **Instructor:** Kuldeep Jiwani (ConcertAI)\n- **When:** Schedule not specified\n- **Why Attend:** This session covers uncertainty in language models, which is highly relevant for knowledge graph-based reasoning and applications.  \n  [Source](#)\n\n---\n\n**3. Fast and Accurate Conversational Agents: Beyond Function Calling**\n- **Instructor:** Daksh Varshneya (Rasa)\n- **When:** Schedule not specified\n- **Why Attend:** Conversational agents often leverage knowledge graphs for context and reasoning, making this session valuable for practical applications.  \n  [Source](#)\n\n---\n\n**4. From Idea to Production with GenAI**\n- **Instructor:** Karan Sindwani (AWS Senior Applied Scientist)\n- **When:** Day 2\n- **Why Attend:** Focuses on productionizing GenAI, which often involves knowledge graph integration for real-world deployments.  \n  [Source](#)\n\n---\n\n**5. Mastering Real-World Agentic AI Applications with AG2 (AutoGen)**\n- **Instructors:** Hrushikesh Dokala (Atlan; fAIght Club), Dr. Qingyun Wu (AG2; Penn State), Chi Wang (AG2; FLAML)\n- **When:** Schedule not specified\n- **Why Attend:** This workshop covers agentic AI applications, which frequently utilize knowledge graphs for memory and reasoning.  \n  [Source](#)\n\n---\n\n**Summary Table**\n\n| Session Title / Topic                                      | Instructor(s)                                   | Date / Schedule           |\n|------------------------------------------------------------|-------------------------------------------------|---------------------------|\n| The Missing Piece of AI Apps: Evaluation                   | Ayush Thakur                                    | 2025-08-21, 16:00–17:00   |\n| Measuring Uncertainty in LLMs and Optimal Use of SLMs      | Kuldeep Jiwani                                  | Not specified             |\n| Fast and Accurate Conversational Agents                    | Daksh Varshneya                                 | Not specified             |\n| From Idea to Production with GenAI                         | Karan Sindwani                                  | Day 2                     |\n| Mastering Real-World Agentic AI Applications with AG2      | Hrushikesh Dokala, Dr. Qingyun Wu, Chi Wang     | Not specified             |\n\n---\n\n**Note:** Only the first session has a precise date and time. For the others, please check the event’s official schedule for updates.  \n[Source: GlobalRetrieval results]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \" Which specific company has the most speakers participating in DHS 2025?\"\n",
        "answer = run_agentic_kag(query)\n",
        "display(Markdown(answer))"
      ],
      "metadata": {
        "id": "VYqciQA1iZKa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "a2faac21-fe2a-4530-fc6d-f913840e5dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ParallelAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To answer this, I need to find a list of speakers for DHS 2025 and identify their company affiliations, then determine which company has the highest number of speakers.\n",
            "Action: GlobalRetrieval\n",
            "Action Input: List of speakers and their company affiliations for DHS 2025\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing communities in parallel: 100%|██████████| 26/26 [00:08<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;1m\u001b[1;3m# List of Speakers and Company Affiliations for DHS 2025\n",
            "\n",
            "Below is a consolidated list of speakers for DHS 2025, along with their company affiliations where available. In several cases, the company affiliation is not specified in the provided data.\n",
            "\n",
            "---\n",
            "\n",
            "## Confirmed Speakers with Company Affiliations\n",
            "\n",
            "- **Syed Quiser Ahmed** — Infosys  \n",
            "- **Kartik Nighania** — Typewise  \n",
            "- **Miguel Otero Pedrido** — The Neural Maze  \n",
            "- **Raghav Bali** — Delivery Hero  \n",
            "- **Hrushikesh Dokala** — Atlan, fAIght Club  \n",
            "- **Dr. Qingyun Wu** — AG2, Penn State  \n",
            "- **Chi Wang** — AG2, FLAML  \n",
            "- **Deepak Sharma** — Google/DeepMind  \n",
            "- **Luis Serrano** — Serrano Academy (prior roles at Google, Apple, Cohere, Zapata)  \n",
            "- **Bhaskarjit Sarmah** — Domyn  \n",
            "- **Praneeth Paikray** — Manpower Group (prior: TCS, Dell, Fidelity)  \n",
            "- **Kuldeep Jiwani** — ConcertAI  \n",
            "- **Daksh Varshneya** — Rasa  \n",
            "- **Pradeep Kumar** — Emirates Airlines  \n",
            "- **Vignesh Kumar** — Google Cloud  \n",
            "- **Pavak Biswal** — Dentsu Global Services (DGS)  \n",
            "- **Abhilash Kulkarni** — Dentsu  \n",
            "- **Arijit Mallick** — Dentsu Global Services (DGS)  \n",
            "- **Praveen Kumar GS** — Samsung Electronics  \n",
            "- **Shubhradeep Nandi** — (Affiliation not specified, but session on finance/welfare)  \n",
            "- **Ayush Thakur** — Weights & Biases (Manager, AI Engineer; Google Developer Expert in ML)  \n",
            "- **Anand S** — Straive/Gramener  \n",
            "- **Aditya Iyengar** — Quanhack  \n",
            "- **Avinash Pathak** — NVIDIA (Senior AI Engineer)  \n",
            "- **Satnam Singh** — Acalvio  \n",
            "- **Shivaraj Mulimani** — Acalvio  \n",
            "- **Karan Sindwani** — AWS (Amazon Web Services)  \n",
            "- **Ashish Tripathy** — Pype AI  \n",
            "- **Mayank Aggarwal** — evolvue AI/CreateHQ  \n",
            "- **Aashay Sachdeva** — Sarvam AI  \n",
            "- **Srikanth Velamakanni** — Fractal (Co-founder & Group CEO; also linked with NASSCOM, Plaksha University, IdeaForge, Metro Brands, BARC India, NIIT Ltd.)  \n",
            "- **Ganesh Subramanian** — Cogentiq  \n",
            "- **Pranjal Singh** — (Affiliation not specified)  \n",
            "- **Anshu Kumar** — (Affiliation not specified)  \n",
            "- **Harshad Khadilkar** — (Affiliation not specified)  \n",
            "- **Nikhil Rana** — (Affiliation not specified)  \n",
            "- **Nitin Agarwal** — (Affiliation not specified)  \n",
            "- **Rutvik Acharya** — (Affiliation not specified)  \n",
            "- **Rohan Rao** — (Affiliation not specified)  \n",
            "- **Joshua Starmer** — (Affiliation not specified)  \n",
            "- **Luis Serrano** — (Affiliation not specified for some sessions)  \n",
            "- **Sanathraj Narayan** — (Affiliation not specified)  \n",
            "- **Prakalp Somawanshi** — (Affiliation not specified)  \n",
            "- **Aashay Sachdeva** — (Affiliation not specified for some sessions)  \n",
            "- **Vijay Gabale** — (Affiliation not specified)  \n",
            "- **Dr. Kiran R** — (Affiliation not specified)  \n",
            "- **Hitesh Nayak** — (Affiliation not specified)  \n",
            "- **Bhaskarjit Sarmah** — (Affiliation not specified for some sessions)  \n",
            "- **Krishnakumar Menon** — (Affiliation not specified)  \n",
            "- **Dipanjan Sarkar** — (Affiliation not specified)\n",
            "\n",
            "---\n",
            "\n",
            "## Additional Organizational Representation\n",
            "\n",
            "- **Microsoft** and **Amazon**: Sessions are led by industry practitioners from these companies, though specific speaker names are not provided.\n",
            "- **Google DeepMind, Uber, Red Hat, NIRAMAI, Tiger Analytics**: Speakers are affiliated with these organizations, indicating a diverse set of industry leaders [Data: Google DeepMind, Uber, Red Hat, NIRAMAI, Tiger Analytics, +more].\n",
            "\n",
            "---\n",
            "\n",
            "## Notes\n",
            "\n",
            "- Some sessions are led by practitioners from major tech, telecom, healthtech, and data/AI services sectors, but individual names are not always specified.\n",
            "- In several cases, only the session or topic is listed without a corresponding company affiliation.\n",
            "\n",
            "---\n",
            "\n",
            "**References:**  \n",
            "[Data: Entities (15, 29, 435, 466, 16, 30, 146, 1285, 1286, 1287, 766, 745, 2593, 639, 1498, 1264, 992, 1666, +more); Relationships (633, 1299, 3, 1226, 3297, 1854, 1815, 1688, +more); Reports (1, Fractal, NASSCOM, Plaksha University, IdeaForge, Metro Brands, Google DeepMind, Uber, Red Hat, NIRAMAI, Tiger Analytics, +more)]\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n",
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I need to count the number of speakers from each company based on the provided affiliations to determine which company has the most speakers.\n",
            "\n",
            "- Dentsu/Dentsu Global Services (DGS): Pavak Biswal, Abhilash Kulkarni, Arijit Mallick (3 speakers)\n",
            "- Google/Google Cloud/DeepMind: Deepak Sharma, Vignesh Kumar (2 speakers; Luis Serrano is ex-Google, not current)\n",
            "- Acalvio: Satnam Singh, Shivaraj Mulimani (2 speakers)\n",
            "- AG2: Dr. Qingyun Wu, Chi Wang (2 speakers)\n",
            "- Atlan/fAIght Club: Hrushikesh Dokala (1 speaker)\n",
            "- Infosys: Syed Quiser Ahmed (1 speaker)\n",
            "- Typewise: Kartik Nighania (1 speaker)\n",
            "- The Neural Maze: Miguel Otero Pedrido (1 speaker)\n",
            "- Delivery Hero: Raghav Bali (1 speaker)\n",
            "- Domyn: Bhaskarjit Sarmah (1 speaker)\n",
            "- Manpower Group: Praneeth Paikray (1 speaker)\n",
            "- ConcertAI: Kuldeep Jiwani (1 speaker)\n",
            "- Rasa: Daksh Varshneya (1 speaker)\n",
            "- Emirates Airlines: Pradeep Kumar (1 speaker)\n",
            "- Samsung Electronics: Praveen Kumar GS (1 speaker)\n",
            "- Weights & Biases: Ayush Thakur (1 speaker)\n",
            "- Straive/Gramener: Anand S (1 speaker)\n",
            "- Quanhack: Aditya Iyengar (1 speaker)\n",
            "- NVIDIA: Avinash Pathak (1 speaker)\n",
            "- AWS: Karan Sindwani (1 speaker)\n",
            "- Pype AI: Ashish Tripathy (1 speaker)\n",
            "- evolvue AI/CreateHQ: Mayank Aggarwal (1 speaker)\n",
            "- Sarvam AI: Aashay Sachdeva (1 speaker)\n",
            "- Fractal: Srikanth Velamakanni (1 speaker)\n",
            "- Cogentiq: Ganesh Subramanian (1 speaker)\n",
            "\n",
            "Dentsu/Dentsu Global Services (DGS) has the most speakers (3) participating in DHS 2025.\n",
            "\n",
            "Final Answer: \n",
            "- **Dentsu/Dentsu Global Services (DGS)** has the most speakers participating in DHS 2025, with three confirmed speakers: Pavak Biswal, Abhilash Kulkarni, and Arijit Mallick [Speaker list and affiliations, see above].\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Dentsu/Dentsu Global Services (DGS)** has the most speakers participating in DHS 2025, with three confirmed speakers: Pavak Biswal, Abhilash Kulkarni, and Arijit Mallick [Speaker list and affiliations, see above]."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \" Tell me one unique session in the conference?\"\n",
        "answer = run_agentic_kag(query)\n",
        "display(Markdown(answer))"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ak_6ExOiMXqa",
        "outputId": "b9b9d6ab-9ab5-47ad-86ab-2e871363033a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ParallelAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To answer this, I need to identify a session in the conference that stands out as unique. I will search for sessions and look for one with distinctive features.\n",
            "Action: GlobalRetrieval\n",
            "Action Input: unique session in the conference\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing communities in parallel: 100%|██████████| 26/26 [00:13<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;1m\u001b[1;3m# Unique Sessions in the Conference\n",
            "\n",
            "The conference features a diverse array of unique sessions, each distinguished by its focus, format, or technical depth. Below is a synthesis of the most notable and distinctive sessions, highlighting their key characteristics and implications.\n",
            "\n",
            "---\n",
            "\n",
            "## 1. **MassGen: Live Multi-Agent Collaboration**\n",
            "A standout session is **MassGen**, which orchestrates a live, real-time collaboration between multiple large language models—Claude, GPT, and Grok. This session is unique in its demonstration of cross-model synergy and parallel workflows, showcasing the combined capabilities of different LLMs in a single, interactive environment. The focus on real-time, multi-agent interaction sets it apart from traditional single-model demonstrations [Data: Entities (370, 847, 1313, 1549, 2591); Relationships (900, 1998, 3756, 1221, 2004)].\n",
            "\n",
            "---\n",
            "\n",
            "## 2. **Hands-On Technical Workshops**\n",
            "Several workshops offer hands-on, production-grade training that distinguishes them from more theoretical sessions:\n",
            "- **Mastering Real-World Agentic AI Applications with AG2 (AutoGen):** This workshop provides practical training on agent design, integration, and deployment using AG2, with a curriculum spanning fundamentals to deployment and covering domains like customer support, marketing, and finance. It emphasizes reliability, security, and maintainability.\n",
            "- **Workshops by Raghav Bali and Joshua Starmer/Luis Serrano:** These full-day sessions cover end-to-end LLMs and AI agents with memory, retrieval, and RL algorithms, offering comprehensive, expert-led instruction.\n",
            "\n",
            "---\n",
            "\n",
            "## 3. **Governance and Responsible AI**\n",
            "Unique governance-focused sessions include:\n",
            "- **PowerTalk by Syed Quiser Ahmed (Infosys):** Focuses on AI governance, setting it apart from technical workshops.\n",
            "- **PowerTalk by Praveen Kumar GS (Samsung Electronics):** Aligns agentic capabilities with responsible design and governance.\n",
            "- **Hack Session by Shubhradeep Nandi:** Operationalizes fairness, explainability, and confidence-aware decisions in finance and welfare contexts.\n",
            "- **Case Study in Medical Imaging:** Applies responsible AI concepts to healthcare [Data: Reports (PowerTalk by Syed Quiser Ahmed, PowerTalk by Praveen Kumar GS, Hack Session by Shubhradeep Nandi, Day 1 sessions, case study in medical imaging)].\n",
            "\n",
            "---\n",
            "\n",
            "## 4. **No-Code and Beginner-Friendly Sessions**\n",
            "- **No-Code Hack Session (Fractal’s Cogentiq):** Enables AI development without coding, making AI accessible to non-technical participants.\n",
            "- **Beginner-Friendly Workshop for Business Leaders:** Tailored for non-technical attendees, focusing on foundational AI concepts.\n",
            "\n",
            "---\n",
            "\n",
            "## 5. **Specialized Hack Sessions and Technical Deep Dives**\n",
            "- **Day 3 Hack Sessions:** One on detecting and mitigating risks in agentic AI (Bhaskarjit Sarmah, Domyn), and another on building a multi-modal generative AI assistant for energy infrastructure inspection (Prakalp Somawanshi), each addressing distinct technical and domain challenges [Data: Reports (1)].\n",
            "- **Scalable LLM Inference Session:** Focuses on technical depth and current AI advancements.\n",
            "- **LangGraph Workshop and Hack Panel:** Deep dive into graph-based agentic workflows and practical framework comparisons.\n",
            "\n",
            "---\n",
            "\n",
            "## 6. **Evaluation, Interoperability, and Protocols**\n",
            "- **Model Context Protocol (MCP) and Agent-to-Agent (A2A) Protocol Sessions:** Focus on standardized tool access and interoperability among AI agents, emphasizing open protocols and enterprise relevance.\n",
            "- **Session on LLM Evaluation (Ayush Thakur, Weights & Biases):** Covers end-to-end evaluation practices, including lifecycle design, human preference alignment, and advanced metrics [Data: Entities (1285, 1286, 1287, 2544, 2541, 1296, 2543, 2542, 1300, 1294, 1301, 1302); Relationships (1226, 3297, 3745, 3749, 3741, 3746, 3748, 3743, 3740, 1241, 1242)].\n",
            "\n",
            "---\n",
            "\n",
            "## 7. **Industry and Application-Focused Sessions**\n",
            "- **Healthcare Voice AI Contact Center:** Demonstrates a production-focused, end-to-end stack for real-time multimodal agents in healthcare.\n",
            "- **Automotive Service AI Workflow (Vignesh Kumar):** Showcases a serverless AI pipeline for large-scale video health checks in automotive services.\n",
            "- **GenAI-Powered CX Playbook (Pavak Biswal & Abhilash Kulkarni):** Focuses on customer retention using a GenAI-powered toolkit for churn detection, sentiment analysis, and more [Data: Reports (1)].\n",
            "\n",
            "---\n",
            "\n",
            "## 8. **Community and Cross-Industry Clusters**\n",
            "- **Analytics Vidhya Leaders Session:** Features a dense cluster of leaders and researchers from Analytics Vidhya, Microsoft, Oracle, and Pure Storage, with cross-industry representation and academic excellence [Data: Entities (4, 731, 311, 516); Relationships (2657, 3274, 3298, 3098)].\n",
            "\n",
            "---\n",
            "\n",
            "## 9. **Other Notable Unique Sessions**\n",
            "- **AWS GenAI Production Practices (Karan Sindwani):** Covers advanced AWS tools and real-world deployment patterns.\n",
            "- **Gemini Venue Sessions:** Include talks on LLM-automated data science, GenAI in Web3, and natural-language data access on Databricks/Snowflake [Data: Entities (766, 745, 639, 2593); Relationships (1854, 1815, 1688)].\n",
            "\n",
            "---\n",
            "\n",
            "## **Implications**\n",
            "These unique sessions collectively demonstrate the conference’s commitment to practical, hands-on learning, cross-model and cross-industry collaboration, responsible AI, and the operationalization of advanced AI systems. The diversity of session formats—from live multi-agent demos to no-code workshops and governance PowerTalks—ensures that both technical and non-technical audiences can engage deeply with the latest in generative and agentic AI.\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n",
            "WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer.\n",
            "Final Answer: \n",
            "\n",
            "**One Unique Session in the Conference**\n",
            "\n",
            "- **MassGen: Live Multi-Agent Collaboration**\n",
            "  - This session is unique because it features a live, real-time collaboration between multiple large language models—Claude, GPT, and Grok.\n",
            "  - It demonstrates cross-model synergy and parallel workflows, showcasing the combined capabilities of different LLMs in a single, interactive environment.\n",
            "  - The focus on real-time, multi-agent interaction sets it apart from traditional single-model demonstrations.  \n",
            "  - [Source: Conference Unique Sessions Overview](#unique-sessions-in-the-conference)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**One Unique Session in the Conference**\n\n- **MassGen: Live Multi-Agent Collaboration**\n  - This session is unique because it features a live, real-time collaboration between multiple large language models—Claude, GPT, and Grok.\n  - It demonstrates cross-model synergy and parallel workflows, showcasing the combined capabilities of different LLMs in a single, interactive environment.\n  - The focus on real-time, multi-agent interaction sets it apart from traditional single-model demonstrations.  \n  - [Source: Conference Unique Sessions Overview](#unique-sessions-in-the-conference)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run all retrievers"
      ],
      "metadata": {
        "id": "BYTefCoLab92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Markdown, display\n",
        "from tools import (\n",
        "    get_rag_for_query_text2cypher,\n",
        "    get_rag_for_query_hybrid,\n",
        "    get_rag_for_query_hybrid_cypher,\n",
        "    global_retriever,\n",
        "    local_search,\n",
        "    community_data,   # required for global_retriever\n",
        ")\n",
        "\n",
        "# Your list of questions\n",
        "complex_questions = [\n",
        "    \"Which company has the most speakers participating in DHS 2025?\",\n",
        "    \"How many Microsoft employees are speaking at DHS 2025, and who are they?\",\n",
        "    \"Identify all sessions where all speakers are from the same organization – name the session and the company\",\n",
        "    \"Name a speaker at DHS 2025 who is involved in more than one session, and list the sessions they are presenting\",\n",
        "    \"What sessions at DHS 2025 have multiple speakers? Provide the session titles along with the speaker names\",\n",
        "    \"Which three companies have the highest number of speakers at DHS 2025?\",\n",
        "    \"Which workshop at DHS 2025 is specifically designed for business leaders, and who is the instructor?\",\n",
        "    \"If you’re interested in “AgentOps”, which session should you attend and who is leading that session?\",\n",
        "    \"List all sessions that explicitly mention “Responsible AI” in their title or theme\",\n",
        "    \"Name two sessions at DHS 2025 that focus on multimodal AI applications\",\n",
        "    \"How many speakers at DHS 2025 hold a title of “Founder” or “Co-Founder”, and can you give two examples of such speakers?\",\n",
        "    \"Which speakers are from NeuralHQ.ai, and which session do they co-present together?\",\n",
        "    \"Joshua Starmer and Luis Serrano are both speaking at DHS 2025. How many sessions is each of them involved in, and what are those sessions?\",\n",
        "    \"What are the titles and who are the speakers of all the Power Talk sessions at DHS 2025?\",\n",
        "    \"If someone wants to learn about LLMs at DHS 2025, which sessions or workshops should they attend (name at least two)?\",\n",
        "    \"Which session is co-presented by an employee from Toast and an employee from Atlassian, and what topic does it cover?\",\n",
        "    \"Provide an example of a session title that is phrased as a question, and name the speaker who is presenting it\",\n",
        "    \"Name two sessions that deal with AI safety or incorporate “guardrails” in AI, and identify their speakers\",\n",
        "    \"Who are the Pure Storage speakers at DHS 2025, and what topics are they presenting?\",\n",
        "    \"Identify sessions that involve AI agent frameworks (such as LangGraph or AG2) and name the speakers leading those sessions\",]\n",
        "\n",
        "theme_based_questions = [\"Which topics are the most frequently covered across all sessions and workshops at DHS 2025?\",\n",
        "    \"What are the top 3 tools used across both workshops and sessions at this year’s conference?\",\n",
        "    \"Which theme connects the largest number of sessions at DHS 2025?\",\n",
        "    \"How many sessions cover LLMs and how many cover agents? Is there any session that covers both?\",\n",
        "    \"Which speakers at DHS 2025 are associated with multiple topics across different formats (session + workshop)?\",\n",
        "    \"What are the most common prerequisites across all workshops this year?\",\n",
        "    \"Identify the clusters of speakers who are part of the same company and covering similar or connected topics\",\n",
        "    \"Which companies are most active in DHS 2025 — across speaking, sponsoring, and conducting workshops?\",\n",
        "    \"What are the top 5 skills or tools attendees will be exposed to if they attend sessions on the Enterprise GenAI theme?\",\n",
        "    \"What are the emerging subfields of GenAI based on the diversity of topics this year?\",\n",
        "    \"How many sessions explicitly deal with ethics, safety, or responsible AI, and who’s leading that conversation?\",\n",
        "    \"What’s the distribution of session difficulty levels (beginner/intermediate/advanced) across the full agenda?\",\n",
        "    \"Which themes are most commonly associated with Power Talks versus Hack Sessions?\",\n",
        "    \"Who are the influential nodes in the speaker network — people connected to many topics, sessions, and organizations?\",\n",
        "    \"Which tools appear only in sessions but not in any workshop, and what might that suggest?\",\n",
        "    \"Identify multi-hop knowledge paths between Arun Prakash Asokan’s session and other speakers working on similar tools or topics\",\n",
        "    \"What are the top 5 most interconnected people in the conference graph, based on session, workshop, and organization links?\",\n",
        "    \"Which organizations have both sponsored and presented sessions or workshops, and what topics do they represent?\",\n",
        "    \"If someone wants to follow only workshops that cover Agentic AI, which ones should they attend and what prerequisites do they need?\",\n",
        "    \"What are the gaps in this year’s conference — for example, highly-discussed topics that have no workshop coverage?\"]\n",
        "\n",
        "simple_questions = [\"On what dates and at which venue is DataHack Summit 2025 being held?\",\n",
        "    \"What is the theme (tagline) of DHS 2025?\",\n",
        "    \"Approximately how many attendees are expected to join DHS 2025 this year?\",\n",
        "    \"Roughly how many AI talks are expected at the conference?\",\n",
        "    \"About how many hack sessions are planned for DHS 2025?\",\n",
        "    \"Name two types of session formats that DHS 2025 will feature (e.g., Keynote, Workshop, etc.)\",\n",
        "    \"Who is delivering the keynote session “Responsible AI in Medical Imaging – A Case Study”?\",\n",
        "    \"Who is Arun? List down all the sessions or workshops delivered by him\",\n",
        "    \"Which founder of StatQuest is speaking at the conference?\",\n",
        "    \"Who is the founder of Serrano Academy that is featured as a speaker at DHS 2025?\",\n",
        "    \"Name one workshop being offered at DHS 2025 (give the title of the workshop)\",\n",
        "    \"Which workshop at DHS 2025 is led by Dipanjan Sarkar?\",\n",
        "    \"Which workshop covers productionalizing real-world applications with LLMs and agents, and who is the instructor?\",\n",
        "    \"Who is giving the Power Talk titled “Revolutionizing AI for Relational Databases: No More Flattening”?\",\n",
        "    \"Name a speaker from NVIDIA who is speaking at DHS 2025\",\n",
        "    \"Is there a Hugging Face engineer speaking at DHS 2025? If yes, who is it?\",\n",
        "    \"Name a speaker from Pure Storage who is speaking at DHS 2025\",\n",
        "    \"Who is presenting the hack session “Quantifying Our Confidence in Neural Networks and AI”?\",\n",
        "    \"What is the title of Pankaj Agarwal’s hack session at DHS 2025?\",\n",
        "    \"What Power Talk is Syed Quiser Ahmed (Infosys) delivering at the summit?\"]\n",
        "\n",
        "\n",
        "medium_questions= [ \"What are the three main focuses of the “AI Trinity” theme at DHS 2025?\",\n",
        "    \"Which DHS 2025 session is co-presented by two speakers from Acalvio Technologies, and what is it called?\",\n",
        "    \"Who are the two Microsoft speakers leading the session on AI Voice Agents, and what are their names?\",\n",
        "    \"Which co-founder of AG2 is conducting a workshop at DHS 2025?\",\n",
        "    \"Name one session title at DHS 2025 that includes “Retrieval-Augmented Generation (RAG)” in its title\",\n",
        "    \"What is the title of the hack session presented by Analytics Vidhya’s Gyan Prakash Tripathi?\",\n",
        "    \"Who is speaking about building a healthcare voice AI contact center (Pipecat) at DHS 2025, and what is the title of that session?\",\n",
        "    \"Who is delivering the Power Talk on evaluating GenAI models in enterprise and healthcare, and which organization is he from?\",\n",
        "    \"Which DHS 2025 session covers aligning Responsible AI with LLMs & Agents, and who is the speaker for it?\",\n",
        "    \"Is there a session on AI agent interoperability protocols (e.g., A2A, MCP) at the conference? If yes, what is its title?\",\n",
        "    \"Who is presenting on building real-world agentic AI systems beyond PoCs, and what is the speaker’s name?\",\n",
        "    \"What session at DHS 2025 focuses on using AI for SEO content generation, and what is it called?\",\n",
        "    \"Who is the Microsoft Generative AI leader speaking at DHS 2025 (name the person)?\",\n",
        "    \"Who is giving the talk titled “Measuring Uncertainty in LLMs and Optimal Use of SLMs”, and what is the speaker’s name?\",\n",
        "    \"Who is discussing multi-agent AI for public travel systems, and which company does that speaker represent?\",\n",
        "    \"Which speaker from Pure Storage is talking about deploying GenAI safely, and what is the title of her talk?\",\n",
        "    \"Give an example of a session title at DHS 2025 that includes the term “Agentic AI” in it\",\n",
        "    \"Who is the Founder & CEO of Analytics Vidhya that is speaking at DHS 2025?\",\n",
        "    \"Name one Oracle speaker who is delivering a Power Talk at DHS 2025\",\n",
        "    \"Joshua Starmer and Luis Serrano are jointly leading which workshop at DHS 2025?\",\n",
        "]\n",
        "\n",
        "example_questions = [\n",
        "    # 1) BASIC RETRIEVAL\n",
        "    \"List all speakers at the conference.\",\n",
        "    \"Display all sessions.\",\n",
        "    \"Show all workshops.\",\n",
        "    \"List all tools.\",\n",
        "    \"List all topics.\",\n",
        "    \"List all venues.\",\n",
        "    \"Show all sponsors.\",\n",
        "    \"List all companies represented.\",\n",
        "    \"List conferences by year.\",\n",
        "    \"List all educational institutions speakers studied at.\",\n",
        "\n",
        "    # 2) DIRECT RELATIONSHIPS\n",
        "    \"Who presents each session?\",\n",
        "    \"Who conducted each workshop?\",\n",
        "    \"Which sessions cover the topic LLMs?\",\n",
        "    \"Which workshops cover Agentic RAG?\",\n",
        "    \"What tools are used in the session titled 'LLM Scalability Challenges'?\",\n",
        "    \"What sessions use LangChain?\",\n",
        "    \"Which workshops use PyTorch?\",\n",
        "    \"Which companies employ speakers attending the conference?\",\n",
        "    \"Show sponsors of DataHack Summit 2025.\",\n",
        "    \"What content is hosted by the conference (sessions & workshops)?\",\n",
        "    \"What is the venue for each session?\",\n",
        "    \"What is the venue for each workshop?\",\n",
        "    \"List hack panel speakers.\",\n",
        "    \"Which speakers present Hack Panel sessions?\",\n",
        "    \"List speakers and their alma maters.\",\n",
        "    \"Which venue hosts the conference?\",\n",
        "\n",
        "    # 3) FILTERING & CONDITIONS\n",
        "    \"List all intermediate-level workshops.\",\n",
        "    \"Find sessions on Day 2.\",\n",
        "    \"Show sessions starting after 10:00 AM on Day 1.\",\n",
        "    \"Show workshops starting after 10:00.\",\n",
        "    \"Sessions between 14:00 and 15:30.\",\n",
        "    \"Sessions that use both LangChain and Neo4j.\",\n",
        "    \"Sessions covering RAG or Agentic RAG.\",\n",
        "    \"Speakers with RAG-related skills.\",\n",
        "    \"Speakers who have awards listed.\",\n",
        "    \"Speakers certified in AWS or Azure.\",\n",
        "    \"Venues hosting more than 3 sessions.\",\n",
        "    \"Topics with at least 5 total sessions/workshops.\",\n",
        "    \"Most used tools across the program.\",\n",
        "    \"Companies with at least two speakers.\",\n",
        "    \"Sponsor counts per conference.\",\n",
        "\n",
        "    # 4) AGGREGATIONS & STATS\n",
        "    \"Count the number of sessions by theme.\",\n",
        "    \"How many workshops did each speaker conduct?\",\n",
        "    \"How many sessions did each speaker present?\",\n",
        "    \"How many hack panel speakers are there?\",\n",
        "    \"Number of sessions per day per venue.\",\n",
        "    \"Top 5 topics by coverage across sessions and workshops.\",\n",
        "    \"For each speaker, how many distinct tools are used in their sessions?\",\n",
        "    \"For each company, how many presenting speakers?\",\n",
        "    \"Average number of sessions per venue.\",\n",
        "    \"Session count by session type.\",\n",
        "\n",
        "    # 5) PATTERN-BASED & RECOMMENDATIONS\n",
        "    \"Recommend workshops for someone interested in LLMs and LangChain.\",\n",
        "    \"Workshops using the same tools as the session 'Graph at Scale'.\",\n",
        "    \"Sessions similar to 'Graph at Scale' by overlapping topics and tools.\",\n",
        "    \"Recommend sessions based on a list of interests (topics).\",\n",
        "    \"Find sessions that do not use any tools.\",\n",
        "    \"Find sessions that cover both RAG and Vector Databases.\",\n",
        "    \"Find sessions covering any of the given topics.\",\n",
        "    \"Who co-presented with a given speaker?\",\n",
        "    \"Sessions presented by speakers from a specific company.\",\n",
        "    \"Beginner workshops covering a given topic.\",\n",
        "    \"Sessions at the Claude venue on Day 1 sorted by time.\",\n",
        "    \"Sessions that use tools used by workshops covering Agentic RAG.\",\n",
        "\n",
        "    # 6) ADVANCED / SUPER-COMPLEX\n",
        "    \"Detect time overlaps between sessions in the same venue (same day).\",\n",
        "    \"Find gaps between consecutive sessions per venue and day.\",\n",
        "    \"Shortest collaboration path between two speakers (up to 6 hops).\",\n",
        "    \"Sessions whose topic and tool sets are supersets of a reference session.\",\n",
        "    \"Return rich session objects with venue, tools, and topics.\",\n",
        "    \"Unified content using tool Neo4j (sessions & workshops).\",\n",
        "    \"Speakers with no company listed.\",\n",
        "    \"Find sessions instructed by Jane Doe (property search).\",\n",
        "    \"Speakers who studied at any of a given list of universities.\",\n",
        "    \"For each topic, list all speakers involved via sessions or workshops.\",\n",
        "    \"Find venues that host both sessions and workshops.\",\n",
        "    \"Which sponsors support more than one conference?\",\n",
        "    \"Detect scheduling conflicts for a specific speaker’s sessions.\",\n",
        "    \"Speakers whose sessions use a given tool.\",\n",
        "    \"Pairs of speakers who studied at the same institution.\",\n",
        "    \"Case-insensitive search for topics by substring.\",\n",
        "    \"Sessions and workshops that cover RAG, including conference context.\",\n",
        "    \"Build a venue-wise session schedule map.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "gHd-SIF1PNbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c3f8e2-0a39-401e-9398-39b4157fd1ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 26 community summaries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "# List of question types to iterate through\n",
        "question_types = {\n",
        "    #\"simple_questions\": simple_questions,\n",
        "    #\"medium_questions\": medium_questions,\n",
        "    #\"complex_questions\": complex_questions,\n",
        "    #\"theme_based_questions\": theme_based_questions,\n",
        "    \"example_questions\": example_questions,\n",
        "}\n",
        "\n",
        "for type_name, questions_list in question_types.items():\n",
        "    print(f\"Running retrievers for {type_name}...\")\n",
        "    results = [] # Reset results for each question type\n",
        "\n",
        "    for q in tqdm(questions_list, desc=f\"Running retrievers for {type_name}\"):\n",
        "        # Print the current question in bold Markdown for clarity\n",
        "        display(Markdown(f\"**Running question:** {q}\"))\n",
        "\n",
        "        try:\n",
        "            text2cypher_answer = get_rag_for_query_text2cypher(q)\n",
        "            print(text2cypher_answer)\n",
        "        except Exception as e:\n",
        "            text2cypher_answer = f\"Error: {e}\"\n",
        "\n",
        "        try:\n",
        "            hybrid_answer = get_rag_for_query_hybrid(q)\n",
        "            print(hybrid_answer)\n",
        "        except Exception as e:\n",
        "            hybrid_answer = f\"Error: {e}\"\n",
        "\n",
        "        try:\n",
        "            hybrid_cypher_answer = get_rag_for_query_hybrid_cypher(q)\n",
        "            print(hybrid_cypher_answer)\n",
        "        except Exception as e:\n",
        "            hybrid_cypher_answer = f\"Error: {e}\"\n",
        "\n",
        "        try:\n",
        "            global_search_answer = global_retriever(q, community_data)\n",
        "        except Exception as e:\n",
        "            global_search_answer = f\"Error: {e}\"\n",
        "\n",
        "        try:\n",
        "            local_search_answer = local_search(q)\n",
        "        except Exception as e:\n",
        "            local_search_answer = f\"Error: {e}\"\n",
        "\n",
        "        # Append row with Markdown answers as raw text\n",
        "        results.append({\n",
        "            \"question\": q,\n",
        "            \"text2cypher_answer\": str(text2cypher_answer),\n",
        "            \"hybrid_answer\": str(hybrid_answer),\n",
        "            \"hybrid_cypher_answer\": str(hybrid_cypher_answer),\n",
        "            \"global_search_answer\": str(global_search_answer),\n",
        "            \"local_search_answer\": str(local_search_answer),\n",
        "        })\n",
        "\n",
        "    # Convert results into DataFrame\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # Save to Excel\n",
        "    output_file = f\"{type_name}_results.xlsx\"\n",
        "    df.to_excel(\"/content/drive/MyDrive/\" +output_file, index=False)\n",
        "\n",
        "    print(f\"✅ Results for {type_name} saved to {output_file}\")"
      ],
      "metadata": {
        "id": "D4M-rUdQgjHk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f28923b-83f2-4b52-f187-6bac2a583570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running retrievers for example_questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRunning retrievers for example_questions:   0%|          | 0/81 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Running question:** List all speakers at the conference."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Mohammad Sanad Zaki Rizvi**\n",
            "  - [LinkedIn Profile](https://www.linkedin.com/in/mohd-sanad-zaki-rizvi-0238b5a6/)\n",
            "\n",
            "*No other speaker names are provided in the context.*\n",
            "<module 'cypher' from '/content/Agentic_KAG/cypher.py'>\n",
            "- **Shivaraj Mulimani** – [LinkedIn](https://www.linkedin.com/in/shivaraj-mulimani-3445b0a9/)\n",
            "- **Satnam Singh** – [LinkedIn](https://www.linkedin.com/in/satnamsinghdatascientist/)\n",
            "- **Vignesh Kumar** – [LinkedIn](https://www.linkedin.com/in/vignesh-kumar-56555a94/)\n",
            "- **Tanika Gupta** – [LinkedIn](https://www.linkedin.com/in/tanika-gupta-78242423/)\n",
            "- **Rutvik Acharya** – [LinkedIn](https://www.linkedin.com/in/rutvikacharya/)\n",
            "- **Nitin Agarwal** – [LinkedIn](https://www.linkedin.com/in/agnitin/)\n",
            "- **Manpreet Singh** – [LinkedIn](https://www.linkedin.com/in/singhmanpreet2517/)\n",
            "- **Syed Quiser Ahmed** – [LinkedIn](https://www.linkedin.com/in/syedquiserahmed/)\n",
            "- **Daksh Varshneya** – [LinkedIn](https://www.linkedin.com/in/dakshvar/)\n",
            "- **Arun Prakash Asokan** – [LinkedIn](https://www.linkedin.com/in/arunprakashasokan/)\n",
            "- **Abhishek Divekar** – [LinkedIn](https://www.linkedin.com/in/ardivekar/)\n",
            "- **Chi Wang** – [LinkedIn](https://www.linkedin.com/in/chi-wang-autogen/)\n",
            "- **Luis Serrano** – [LinkedIn](https://www.linkedin.com/in/luisgserrano/)\n",
            "- **Dhruv Nair** – [LinkedIn](https://www.linkedin.com/in/dhruvnair/)\n",
            "- **Ashish Tripathy** – [LinkedIn](https://www.linkedin.com/in/ashish-tripathy-70a30863/)\n",
            "- **Krishnakumar Menon** – [LinkedIn](https://www.linkedin.com/in/menonkrishna/)\n",
            "- **Krishna Kumar Tiwari** – [LinkedIn](https://www.linkedin.com/in/agentkk/)\n",
            "- **Deepak Sharma** – [LinkedIn](https://www.linkedin.com/in/deepaksharma09/)\n",
            "- **Miguel Otero Pedrido** – [LinkedIn](https://www.linkedin.com/in/migueloteropedrido/)\n",
            "- **Anand S** – [LinkedIn](https://www.linkedin.com/in/sanand0/)\n",
            "- **Anuvrat Parashar** – [LinkedIn](https://www.linkedin.com/in/anuvratparashar/)\n",
            "- **Kunal Jain** – [LinkedIn](https://www.linkedin.com/in/jaink/)\n",
            "- **Ravi RS Nadimpalli** – [LinkedIn](https://www.linkedin.com/in/ever-loyal/)\n",
            "- **Bhaskarjit Sarmah** – [LinkedIn](https://www.linkedin.com/in/bhaskarjitsarmah/)\n",
            "- **Ruchi Awasthi** – [LinkedIn](https://www.linkedin.com/in/ruchiawasthi63/)\n",
            "- **Anuj Saini** – [LinkedIn](https://www.linkedin.com/in/anuj-saini-23666211/)\n",
            "- **Prakalp Somawanshi** – [LinkedIn](https://www.linkedin.com/in/prakalpsomawanshi/?originalSubdomain=in)\n",
            "- **Ranjani Mani** – [LinkedIn](https://www.linkedin.com/in/ranjanimani/)\n",
            "- **Manoranjan Rajguru** – [LinkedIn](https://www.linkedin.com/in/manoranjan-rajguru/)\n",
            "- **Hitesh Nayak** – [LinkedIn](https://www.linkedin.com/in/hitesh-nayak/)\n",
            "- **Sanathraj Narayan** – [LinkedIn](https://www.linkedin.com/in/sanathrajnarayan/)\n",
            "- **Joshua Starmer** – [LinkedIn](https://www.linkedin.com/in/joshua-starmer-phd/)\n",
            "- **Mayank Aggarwal** – [LinkedIn](https://www.linkedin.com/in/mayank953/)\n",
            "- **Praneeth Paikray** – [LinkedIn](https://www.linkedin.com/in/praneeth-paikray/)\n",
            "- **Dipanjan Sarkar** – [LinkedIn](https://www.linkedin.com/in/dipanjans/)\n",
            "- **Praveen Kumar GS** – [LinkedIn](https://www.linkedin.com/in/praveenreddy007/)\n",
            "- **Vijay Gabale** – [LinkedIn](https://www.linkedin.com/in/vijaygabale/)\n",
            "- **Saurav Agarwal** – [LinkedIn](https://www.linkedin.com/in/sauravagarwal/)\n",
            "- **Avinash Pathak** – [LinkedIn](https://www.linkedin.com/in/avipathak99/)\n",
            "- **Jayita Bhattacharyya** – [LinkedIn](https://www.linkedin.com/in/jayita-bhattacharyya/)\n",
            "- **Pradeep Kumar** – [LinkedIn](https://www.linkedin.com/in/prady00/)\n",
            "- **Kartik Nighania** – [LinkedIn](https://www.linkedin.com/in/kartik-nighania-765227145/)\n",
            "- **Alessandro Romano** – [LinkedIn](https://www.linkedin.com/in/alessandro-romano-1990/)\n",
            "- **Gauri Kholkar** – [LinkedIn](https://www.linkedin.com/in/gaurikholkar)\n",
            "- **Aashay Sachdeva** – [LinkedIn](https://www.linkedin.com/in/aashay-sachdeva-020806b7/)\n",
            "- **Atul Ramesh Deshpande** – [LinkedIn](https://www.linkedin.com/in/atulrdeshpande/)\n",
            "- **Aditya Iyengar** – [LinkedIn](https://www.linkedin.com/in/aditya-iyengar/)\n",
            "- **Shubhradeep Nandi** – [LinkedIn](https://www.linkedin.com/in/shubhradeepnandi/?originalSubdomain=in)\n",
            "- **Ayush Thakur** – [LinkedIn](https://www.linkedin.com/in/ayush-thakur-731914149/)\n",
            "- **Kuldeep Jiwani** – [LinkedIn](https://www.linkedin.com/in/kuldeep-jiwani/)\n",
            "- **Ganesh Subramanian** – [LinkedIn](https://www.linkedin.com/in/ganesh1986/)\n",
            "- **Dr. Kiran R** – [LinkedIn](https://www.linkedin.com/in/rkirana/)\n",
            "- **Nikhil Rana** – [LinkedIn](https://www.linkedin.com/in/nikhilrana9/)\n",
            "- **Abhilash Kulkarni** – [LinkedIn](https://www.linkedin.com/in/abhilash-kulkarni-/)\n",
            "- **Pavak Biswal** – [LinkedIn](https://www.linkedin.com/in/pavakbiswal/)\n",
            "- **Karan Sindwani** – [LinkedIn](https://www.linkedin.com/in/karansindwani/)\n",
            "- **Harshad Khadilkar** – [LinkedIn](https://www.linkedin.com/in/harshad-khadilkar-80609959/)\n",
            "- **Pankaj Agarwal** – [LinkedIn](https://www.linkedin.com/in/pankaj-agarwal-b5762318/)\n",
            "- **Arijit Mallick** – [LinkedIn](https://www.linkedin.com/in/arijitmallick/)\n",
            "- **Rohan Rao** – [LinkedIn](https://www.linkedin.com/in/magras193/)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing communities in parallel:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "Processing communities in parallel:   4%|▍         | 1/26 [00:00<00:21,  1.18it/s]\u001b[A\n",
            "Processing communities in parallel:   8%|▊         | 2/26 [00:01<00:11,  2.06it/s]\u001b[A\n",
            "Processing communities in parallel:  12%|█▏        | 3/26 [00:01<00:08,  2.71it/s]\u001b[A\n",
            "Processing communities in parallel:  19%|█▉        | 5/26 [00:01<00:05,  4.14it/s]\u001b[A\n",
            "Processing communities in parallel:  23%|██▎       | 6/26 [00:02<00:07,  2.82it/s]\u001b[A\n",
            "Processing communities in parallel:  27%|██▋       | 7/26 [00:02<00:05,  3.27it/s]\u001b[A\n",
            "Processing communities in parallel:  35%|███▍      | 9/26 [00:02<00:03,  4.74it/s]\u001b[A\n",
            "Processing communities in parallel:  38%|███▊      | 10/26 [00:02<00:03,  4.18it/s]\u001b[A\n",
            "Processing communities in parallel:  42%|████▏     | 11/26 [00:03<00:03,  4.14it/s]\u001b[A\n",
            "Processing communities in parallel:  46%|████▌     | 12/26 [00:03<00:03,  4.13it/s]\u001b[A\n",
            "Processing communities in parallel:  54%|█████▍    | 14/26 [00:03<00:02,  5.45it/s]\u001b[A\n",
            "Processing communities in parallel:  62%|██████▏   | 16/26 [00:04<00:02,  3.86it/s]\u001b[A\n",
            "Processing communities in parallel:  65%|██████▌   | 17/26 [00:04<00:02,  4.34it/s]\u001b[A\n",
            "Processing communities in parallel:  69%|██████▉   | 18/26 [00:04<00:02,  3.80it/s]\u001b[A\n",
            "Processing communities in parallel:  73%|███████▎  | 19/26 [00:05<00:02,  3.46it/s]\u001b[A\n",
            "Processing communities in parallel:  77%|███████▋  | 20/26 [00:05<00:01,  3.98it/s]\u001b[A\n",
            "Processing communities in parallel:  81%|████████  | 21/26 [00:05<00:01,  4.76it/s]\u001b[A\n",
            "Processing communities in parallel:  85%|████████▍ | 22/26 [00:05<00:00,  4.52it/s]\u001b[A\n",
            "Processing communities in parallel:  92%|█████████▏| 24/26 [00:06<00:00,  3.01it/s]\u001b[A\n",
            "Processing communities in parallel: 100%|██████████| 26/26 [00:06<00:00,  3.78it/s]\n",
            "Running retrievers for example_questions:   1%|          | 1/81 [01:12<1:36:16, 72.20s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Running question:** Display all sessions."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Secure database connections and authentication**\n",
            "  - No additional session details provided.\n",
            "\n",
            "- **Mastering Agentic Workflows with LangGraph**\n",
            "  - **Instructor:** Sanathraj Narayan\n",
            "  - **Date:** 2025-08-22\n",
            "  - **Day:** Day 3\n",
            "  - **Time:** 10:25 – 11:15\n",
            "  - **Type:** Hack Session\n",
            "  - **Tools Discussed:** LangGraph\n",
            "  - **Description:** Building graph-based LLM workflows, agent architectures with memory and tools, reflexion loops, agentic RAG, tracing, and experiment tracking.\n",
            "\n",
            "- **Visualizations from natural language queries**\n",
            "  - No additional session details provided.\n",
            "\n",
            "- **Architecting AI: Practical Patterns for Multi-Agentic Workflows**\n",
            "  - **Instructor:** Pranjal Singh\n",
            "  - **Date:** 2025-08-22\n",
            "  - **Day:** Day 3\n",
            "  - **Time:** 13:10 – 14:00\n",
            "  - **Type:** Hack Session\n",
            "  - **Theme:** Agentic workflows and multi-agent systems\n",
            "  - **Tools Discussed:** LLMs, VLMs, OCR, Audio processing\n",
            "  - **Description:** Hands-on, code-rich session on design patterns for multi-agent systems, agent interaction structures, structured outputs, task guardrails, grounding with multimodal models, and demos including coordination, extraction, summarization, translation, and more.\n",
            "\n",
            "- **Mohammad Sanad Zaki Rizvi**\n",
            "  - **Designation:** Senior AI Scientist at Analytics Vidhya\n",
            "  - **Bio:** Specializes in NLP, LLMs, hallucination mitigation, multilingual NLP, low-resource language modeling, and deep learning. Experienced in top research labs and passionate about open-source NLP tools and responsible AI.\n",
            "  - **LinkedIn:** [Mohammad Sanad Zaki Rizvi](https://www.linkedin.com/in/mohd-sanad-zaki-rizvi-0238b5a6/)\n",
            "<module 'cypher' from '/content/Agentic_KAG/cypher.py'>\n",
            "- **Opening Remarks**\n",
            "  - Type: Opening Remark\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 10:00 - 10:20\n",
            "\n",
            "- **Responsible AI in Medical Imaging – A Case Study**\n",
            "  - Type: Case Study\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 10:20 - 11:20\n",
            "\n",
            "- **Productionizing Agents : An Agent Factory Approach**\n",
            "  - Type: PowerTalk\n",
            "  - Instructor: Krishnakumar Menon\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 11:00 - 11:15\n",
            "\n",
            "- **AV Luminary Awards - Top 7 GenAI Leaders**\n",
            "  - Type: Awards\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 11:20 - 11:40\n",
            "\n",
            "- **Agents at Scale: Engineering Reliable GenAI Systems for Production**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Kartik Nighania\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 12:00 - 12:50\n",
            "\n",
            "- **Agentic Knowledge Augmented Generation: The Next Leap After RAG**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Arun Prakash Asokan\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 12:00 - 12:50\n",
            "\n",
            "- **Onboarding AI Agents with Human Values**\n",
            "  - Type: PowerTalk\n",
            "  - Instructor: Syed Quiser Ahmed\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 12:00 - 12:40\n",
            "\n",
            "- **Building Blocks of Successful AI**\n",
            "  - Type: PowerTalk\n",
            "  - Instructor: Arijit Mallick\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 12:00 - 12:40\n",
            "  - [Session Link](/datahacksummit-2025/sessions/building-blocks-of-successful-ai)\n",
            "\n",
            "- **Building Effective Agentic AI Systems: Lessons from the Field**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Dipanjan Sarkar\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 12:45 - 13:35\n",
            "\n",
            "- **Measuring Uncertainty in LLMs and Optimal Use of SLMs**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Kuldeep Jiwani\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 12:55 - 13:45\n",
            "\n",
            "- **Building a Scalable Healthcare Voice AI Contact Center with Pipecat**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Ashish Tripathy\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 12:55 - 13:45\n",
            "\n",
            "- **Aligning Responsible AI with Probabilistic World of LLMs & Agents**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Shubhradeep Nandi\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 14:15 - 15:05\n",
            "\n",
            "- **vLLM + llm-d: Scalable, Efficient LLM Inference in Kubernetes**\n",
            "  - Type: PowerTalk\n",
            "  - Instructor: Atul Ramesh Deshpande\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 14:25 - 15:05\n",
            "\n",
            "- **Human-In-The-Loop Agentic Systems**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Deepak Sharma\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 14:35 - 15:25\n",
            "\n",
            "- **Agentic AI Meets Responsible AI: Designing Safe Autonomous Systems**\n",
            "  - Type: PowerTalk\n",
            "  - Instructor: Praveen Kumar GS\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 14:45 - 15:25\n",
            "\n",
            "- **Bridging the AI Agent Gap: Interoperability with A2A and MCP Protocols**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Nikhil Rana\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 15:30 - 16:20\n",
            "  - [Session Link](/datahacksummit-2025/sessions/bridging-the-ai-agent-gap-interoperability-with-a2a-and-mcp-protocols)\n",
            "\n",
            "- **Evolution of Intelligence & You**\n",
            "  - Type: Keynote\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 15:30 - 16:20\n",
            "\n",
            "- **Automating Vehicle Inspections with Multimodal AI and Gemini on GCP**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Vignesh Kumar\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 16:25 - 17:15\n",
            "\n",
            "- **Vibe Coding in Action: Building Real Applications with AI Assistance**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Tanika Gupta\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 16:40 - 17:30\n",
            "  - [Session Link](/datahacksummit-2025/sessions/vibe-coding-in-action-building-real-applications-with-ai-assistance)\n",
            "\n",
            "- **Deploying GenAI Safely: Strategies for Trustworthy LLMs**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Gauri Kholkar\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 16:40 - 17:30\n",
            "\n",
            "- **Collaborative Multi-Agent Framework for Robust SEO Content Generation**\n",
            "  - Type: Hack Session\n",
            "  - Instructor: Anshu Kumar\n",
            "  - Date: 2025-08-20\n",
            "  - Day: Day 1\n",
            "  - Time: 16:40 - 17:30\n",
            "\n",
            "---\n",
            "\n",
            "**Note:** The above list includes all unique sessions from the provided context, with their titles, types, instructors (if available), dates, days, and times. Sessions with explicit URLs are included as clickable links.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing communities in parallel:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "Processing communities in parallel:   4%|▍         | 1/26 [00:01<00:40,  1.60s/it]\u001b[A\n",
            "Processing communities in parallel:   8%|▊         | 2/26 [00:01<00:18,  1.33it/s]\u001b[A\n",
            "Processing communities in parallel:  15%|█▌        | 4/26 [00:02<00:11,  1.98it/s]\u001b[A\n",
            "Processing communities in parallel:  19%|█▉        | 5/26 [00:02<00:09,  2.11it/s]\u001b[A\n",
            "Processing communities in parallel:  27%|██▋       | 7/26 [00:03<00:07,  2.70it/s]\u001b[A\n",
            "Processing communities in parallel:  31%|███       | 8/26 [00:03<00:05,  3.06it/s]\u001b[A\n",
            "Processing communities in parallel:  38%|███▊      | 10/26 [00:04<00:04,  3.41it/s]\u001b[A\n",
            "Processing communities in parallel:  42%|████▏     | 11/26 [00:04<00:04,  3.37it/s]\u001b[A\n",
            "Processing communities in parallel:  46%|████▌     | 12/26 [00:04<00:03,  3.85it/s]\u001b[A\n",
            "Processing communities in parallel:  50%|█████     | 13/26 [00:05<00:04,  2.68it/s]\u001b[A\n",
            "Processing communities in parallel:  54%|█████▍    | 14/26 [00:05<00:03,  3.13it/s]\u001b[A\n",
            "Processing communities in parallel:  62%|██████▏   | 16/26 [00:06<00:03,  3.00it/s]\u001b[A\n",
            "Processing communities in parallel:  65%|██████▌   | 17/26 [00:06<00:03,  2.76it/s]\u001b[A\n",
            "Processing communities in parallel:  69%|██████▉   | 18/26 [00:07<00:03,  2.33it/s]\u001b[A\n",
            "Processing communities in parallel:  73%|███████▎  | 19/26 [00:07<00:02,  2.67it/s]\u001b[A\n",
            "Processing communities in parallel:  81%|████████  | 21/26 [00:07<00:01,  4.21it/s]\u001b[A\n",
            "Processing communities in parallel:  85%|████████▍ | 22/26 [00:08<00:01,  3.32it/s]\u001b[A\n",
            "Processing communities in parallel:  88%|████████▊ | 23/26 [00:09<00:01,  2.08it/s]\u001b[A\n",
            "Processing communities in parallel:  92%|█████████▏| 24/26 [00:09<00:00,  2.10it/s]\u001b[A\n",
            "Processing communities in parallel:  96%|█████████▌| 25/26 [00:10<00:00,  1.92it/s]\u001b[A\n",
            "Processing communities in parallel: 100%|██████████| 26/26 [00:11<00:00,  2.18it/s]\n",
            "Running retrievers for example_questions:   2%|▏         | 2/81 [03:11<2:11:45, 100.07s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Running question:** Show all workshops."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Mastering LLMs: Training, Fine-Tuning, and Best Practices**\n",
            "  - **Instructor:** Raghav Bali\n",
            "  - **Date:** 23-08-2025\n",
            "  - **Time:** 09:30 – 17:30\n",
            "  - **Description:** Comprehensive, hands-on workshop covering LLM fundamentals to advanced practices, including transformers, pre-training, fine-tuning, PEFT, LoRA, RLHF, prompt engineering, RAGs, DSPy, and tool-calling through MCP. Aimed at working professionals and accessible to beginners.\n",
            "  - **Prerequisites:**\n",
            "    - Basics/hands-on experience of working with Python\n",
            "    - Basic understanding of Deep Neural Networks (preferably PyTorch)\n",
            "    - Access to Google Colab or similar Python environment with GPU access\n",
            "  - **Tools Used:** BERT, GPT2, LLaMA3, Gemma, OpenAI models, DSPy, MCP\n",
            "\n",
            "- **Mastering Real-World Multi-Agent Systems**\n",
            "  - **Instructor:** Alessandro Romano\n",
            "  - **Date:** 23-08-2025\n",
            "  - **Time:** 09:30 – 17:30\n",
            "  - **Description:** Hands-on workshop exploring multi-agent orchestration using CrewAI in Python, covering agent creation, orchestration strategies, tool integration (including custom tools), LLM-agnostic setups, and integrating CrewAI with external libraries like Streamlit to build real-world workflows.\n",
            "  - **Prerequisites:**\n",
            "    - Basic Python knowledge (e.g., installing packages, creating environments, defining classes)\n",
            "    - OpenAI API key (or another LLM provider)\n",
            "    - Serper.dev API key\n",
            "  - **Tools Used:** CrewAI, Python, Streamlit, OpenAI API, Serper.dev API, mem0, virtualenv, conda\n",
            "  - **Modules:**\n",
            "    - Introduction to CrewAI and Multi-Agent Systems\n",
            "    - Get Started with CrewAI – Hands-On Fundamentals\n",
            "    - Content Creation with Guardrails using Flows\n",
            "    - Fraud Detection with Pattern Recognition Agents\n",
            "    - Intelligent Onboarding & Persistent Memory with Mem0\n",
            "    - Final Project – Conversational Agent with Streamlit and Voice I/O\n",
            "\n",
            "- **Agentic AI & Generative AI for Business Leaders**\n",
            "  - **Instructor:** David Zakkam\n",
            "  - **Date:** 23-08-2025\n",
            "  - **Time:** 09:30 – 17:30\n",
            "  - **Level:** Beginner\n",
            "  - **Description:** Full-day workshop for business and enterprise leaders to demystify AI and ML concepts through simple explanations, real-world examples, and live demos. Covers actionable GenAI use cases, prompting for better business outcomes, foundational techniques, and strategic adoption roadmaps—no technical background required.\n",
            "  - **Prerequisites:**\n",
            "    - No technical expertise is necessary\n",
            "    - Understanding basic business processes across functions\n",
            "  - **Modules:**\n",
            "    - Module 1: Opening\n",
            "\n",
            "- **Long-running collaboration workflows**\n",
            "  - **No instructor specified**\n",
            "  - **Description:** (No detailed description provided)\n",
            "<module 'cypher' from '/content/Agentic_KAG/cypher.py'>\n",
            "**All Workshops**\n",
            "\n",
            "- **Mastering Intelligent Agents: A Deep Dive into Agentic AI**\n",
            "  - Instructor: Dipanjan Sarkar\n",
            "  - Date: 23-08-2025\n",
            "  - Time: 09:30 – 17:30\n",
            "  - Description: Hands-on, full-day workshop covering concepts and practical patterns for Agentic AI Systems, including tool-use, reflection, planning, and multi-agent design. Participants build agents with industry-standard frameworks and learn deployment, debugging, and monitoring.\n",
            "  - Tools Used: LangChain, LangGraph, CrewAI, FastAPI, LangFuse, Arize AI Phoenix, Tavily, WeatherAPI, Google Colab, Runpod.io, LangMem, Mem0\n",
            "  - Prerequisites: Python, NLP, Generative AI\n",
            "\n",
            "- **Mastering Real-World Multi-Agent Systems**\n",
            "  - Instructor: Alessandro Romano\n",
            "  - Date: 23-08-2025\n",
            "  - Time: 09:30 – 17:30\n",
            "  - Description: Hands-on workshop exploring multi-agent orchestration using CrewAI in Python, covering agent creation, orchestration strategies, tool integration (including custom tools), LLM-agnostic setups, and integrating CrewAI with external libraries like Streamlit to build real-world workflows.\n",
            "  - Tools Used: CrewAI, Python, Streamlit, OpenAI API, Serper.dev API, mem0, virtualenv, conda\n",
            "  - Prerequisites: Basic Python knowledge, OpenAI API key (or another LLM provider), Serper.dev API key\n",
            "  - Modules: Introduction to CrewAI and Multi-Agent Systems, Get Started with CrewAI – Hands-On Fundamentals, Content Creation with Guardrails using Flows, Fraud Detection with Pattern Recognition Agents, Intelligent Onboarding & Persistent Memory with Mem0, Final Project – Conversational Agent with Streamlit and Voice I/O\n",
            "\n",
            "- **Mastering Real-World Agentic AI Applications with AG2 (AutoGen)**\n",
            "  - Instructors: Hrushikesh Dokala, Qingyun Wu, Chi Wang\n",
            "  - Date: 23-08-2025\n",
            "  - Time: 09:30 – 17:30\n",
            "  - Description: Hands-on technical workshop to master building production-grade AI agent applications with AG2 (formerly AutoGen), an open-source AI Agent framework. Explore agent design patterns, customize agents for specific domains, and learn production deployment strategies using FastAgency.\n",
            "  - Tools Used: AG2 (AutoGen), FastAgency, MCP, Python, Git\n",
            "  - Prerequisites: Basic Python programming knowledge, Familiarity with LLMs, GitHub account, Local development environment with Python 3.9+\n",
            "\n",
            "- **LLMOps – Productionalizing Real-World Applications with LLMs and Agents**\n",
            "  - Instructor: Kartik Nighania\n",
            "  - Date: 23 August 2025\n",
            "  - Time: 09:30 – 17:30\n",
            "  - Description: Hands-on session guiding through training language models using HuggingFace, building RAG pipelines with Qdrant, deploying workflows on Amazon SageMaker, orchestrating multi-agent workflows with LangGraph, and testing with LangSmith.\n",
            "  - Tools Used: Hugging Face, Qdrant, Amazon SageMaker, LangGraph, LangSmith, LangChain, AWS\n",
            "  - Prerequisites: Basic Python programming skills, Basic understanding of machine learning concepts, Familiarity with AWS services\n",
            "\n",
            "- **Mastering LLMs: Training, Fine-Tuning, and Best Practices**\n",
            "  - Instructor: Raghav Bali\n",
            "  - Date: 23-08-2025\n",
            "  - Time: 09:30 – 17:30\n",
            "  - Description: Comprehensive, hands-on workshop covering LLM fundamentals to advanced practices, including transformers, pre-training, fine-tuning, PEFT, LoRA, RLHF, prompt engineering, RAGs, DSPy, and tool-calling through MCP.\n",
            "  - Tools Used: BERT, GPT2, LLaMA3, Gemma, OpenAI models, DSPy, MCP\n",
            "  - Prerequisites: Basics/hands-on experience with Python, Basic understanding of Deep Neural Networks (preferably PyTorch), Access to Google Colab or similar environment with GPU\n",
            "\n",
            "- **AgentOps: Building and Deploying AI Agents**\n",
            "  - Instructor: Bhaskarjit Sarmah\n",
            "  - Date: 23-08-2025\n",
            "  - Time: 09:30 – 17:30\n",
            "  - Description: Hands-on workshop introducing AgentOps focused on operationalizing AI agents for production. Covers agent architecture, tool integration, memory management, task orchestration, multi-agent systems, Agentic RAG, and evaluation.\n",
            "  - Tools Used: LangChain, LangGraph\n",
            "  - Prerequisites: Basic understanding of AI/ML and LLMs, Familiarity with Python and frameworks like LangChain or LangGraph, Experience with APIs and web-based tool integrations\n",
            "\n",
            "- **From Beginner to Expert: Learning LLMs, Reinforcement Learning & AI Agents**\n",
            "  - Instructors: Joshua Starmer, Luis Serrano\n",
            "  - Date: 23-08-2025\n",
            "  - Time: 09:30 – 17:30\n",
            "  - Description: Hands-on workshop covering LLMs, Reinforcement Learning, RLHF, RAG, and Agentic AI. Participants will build, train, and fine-tune decoder-only transformers, implement RL algorithms, and construct a RAG pipeline and basic AI agents.\n",
            "  - Tools Used: PyTorch, Vector database, Rerank tool, APIs, Code execution\n",
            "  - Prerequisites: Basic Python programming skills\n",
            "  - **Note:** Tentative\n",
            "\n",
            "- **Building Intelligent Multimodal Agents: Integrating Vision, Speech & Language**\n",
            "  - Instructor: Miguel Otero Pedrido\n",
            "  - Date: 23-08-2025\n",
            "  - Time: 09:30 – 17:30\n",
            "  - Description: Hands-on workshop to build a fully functional multimodal Telegram agent using an agentic AI stack. Includes vision, speech, and language integration.\n",
            "  - Tools Used: LangGraph, LangGraph Studio, SQLite, Qdrant, Groq LLMs, Whisper, ElevenLabs, Llama 3.2 Vision, Diffusion Models, Telegram Bot API, Telegram\n",
            "  - Prerequisites: Basic Python programming skills, Familiarity with LangChain or LangGraph, Basic understanding of multimodal AI concepts\n",
            "  - **Note:** These are tentative details and are subject to change.\n",
            "  - **URL:** [Building a Multimodal Telegram Agent That Sees, Talks, and Thinks](/datahacksummit-2025/workshops/building-a-multimodal-telegram-agent-that-sees-talks-and-thinks)\n",
            "\n",
            "- **Agentic AI & Generative AI for Business Leaders**\n",
            "  - Instructor: David Zakkam\n",
            "  - Date: 23-08-2025\n",
            "  - Time: 09:30 – 17:30\n",
            "  - Description: Full-day workshop for business and enterprise leaders to demystify AI and ML concepts, uncover actionable GenAI use cases, and explore strategic adoption roadmaps.\n",
            "  - Prerequisites: No technical expertise is necessary, Understanding basic business processes across functions\n",
            "  - Level: Beginner\n",
            "\n",
            "- **Agentic RAG Workshop: From Fundamentals to Real-World Implementations**\n",
            "  - Instructor: Arun Prakash Asokan\n",
            "  - Start Time: 09:30\n",
            "  - Description: Deep dive into Agentic RAG (Retrieval-Augmented Generation) combining LLM-based agents with retrieval techniques. Includes hands-on practice in Google Colab using Azure Document Intelligence, Chroma Vector DB, LangChain, LangGraph, and Langfuse.\n",
            "  - Tools Used: Google Colab notebooks, Azure Document Intelligence, Chroma Vector DB, LangChain, LangGraph, Langfuse, Travily web search, Neo4j\n",
            "  - Prerequisites: Basic Python skills, Introductory level exposure to LLMs and RAG, Familiarity with LangChain or similar frameworks, Exposure to vector databases and embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing communities in parallel:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "Processing communities in parallel:   4%|▍         | 1/26 [00:01<00:32,  1.29s/it]\u001b[A\n",
            "Processing communities in parallel:   8%|▊         | 2/26 [00:01<00:14,  1.64it/s]\u001b[A\n",
            "Processing communities in parallel:  15%|█▌        | 4/26 [00:01<00:06,  3.20it/s]\u001b[A\n",
            "Processing communities in parallel:  19%|█▉        | 5/26 [00:02<00:07,  2.86it/s]\u001b[A\n",
            "Processing communities in parallel:  23%|██▎       | 6/26 [00:02<00:05,  3.59it/s]\u001b[A\n",
            "Processing communities in parallel:  27%|██▋       | 7/26 [00:02<00:05,  3.41it/s]\u001b[A\n",
            "Processing communities in parallel:  35%|███▍      | 9/26 [00:02<00:03,  4.46it/s]\u001b[A\n",
            "Processing communities in parallel:  38%|███▊      | 10/26 [00:03<00:04,  3.77it/s]\u001b[A\n",
            "Processing communities in parallel:  42%|████▏     | 11/26 [00:03<00:03,  3.95it/s]\u001b[A\n",
            "Processing communities in parallel:  46%|████▌     | 12/26 [00:03<00:03,  3.83it/s]\u001b[A\n",
            "Processing communities in parallel:  50%|█████     | 13/26 [00:04<00:03,  3.66it/s]\u001b[A\n",
            "Processing communities in parallel:  54%|█████▍    | 14/26 [00:04<00:04,  2.82it/s]\u001b[A\n",
            "Processing communities in parallel:  62%|██████▏   | 16/26 [00:04<00:02,  4.34it/s]\u001b[A\n",
            "Processing communities in parallel:  65%|██████▌   | 17/26 [00:05<00:02,  3.60it/s]\u001b[A\n",
            "Processing communities in parallel:  69%|██████▉   | 18/26 [00:05<00:02,  3.78it/s]\u001b[A\n",
            "Processing communities in parallel:  73%|███████▎  | 19/26 [00:05<00:01,  3.74it/s]\u001b[A\n",
            "Processing communities in parallel:  77%|███████▋  | 20/26 [00:05<00:01,  3.63it/s]\u001b[A\n",
            "Processing communities in parallel:  85%|████████▍ | 22/26 [00:06<00:00,  4.10it/s]\u001b[A\n",
            "Processing communities in parallel:  88%|████████▊ | 23/26 [00:06<00:00,  4.63it/s]\u001b[A\n",
            "Processing communities in parallel:  96%|█████████▌| 25/26 [00:07<00:00,  3.41it/s]\u001b[A\n",
            "Processing communities in parallel: 100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n",
            "Running retrievers for example_questions:   4%|▎         | 3/81 [06:16<3:00:33, 138.90s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Running question:** List all tools."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Write-Select-Compress-Isolate framework**\n",
            "- **Agent architectures with memory and tools**\n",
            "- **RAHAT (Responsive AI Helper and Tasker)**\n",
            "<module 'cypher' from '/content/Agentic_KAG/cypher.py'>\n",
            "- **Garak**\n",
            "- **PyRIT**\n",
            "- **ART**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing communities in parallel:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "Processing communities in parallel:   4%|▍         | 1/26 [00:01<00:30,  1.22s/it]\u001b[A\n",
            "Processing communities in parallel:  12%|█▏        | 3/26 [00:01<00:10,  2.25it/s]\u001b[A\n",
            "Processing communities in parallel:  19%|█▉        | 5/26 [00:01<00:06,  3.16it/s]\u001b[A\n",
            "Processing communities in parallel:  23%|██▎       | 6/26 [00:02<00:07,  2.84it/s]\u001b[A\n",
            "Processing communities in parallel:  31%|███       | 8/26 [00:03<00:06,  2.85it/s]\u001b[A\n",
            "Processing communities in parallel:  35%|███▍      | 9/26 [00:03<00:05,  3.21it/s]\u001b[A\n",
            "Processing communities in parallel:  38%|███▊      | 10/26 [00:03<00:06,  2.52it/s]\u001b[A\n",
            "Processing communities in parallel:  42%|████▏     | 11/26 [00:04<00:04,  3.09it/s]\u001b[A\n",
            "Processing communities in parallel:  46%|████▌     | 12/26 [00:04<00:04,  3.39it/s]\u001b[A\n",
            "Processing communities in parallel:  50%|█████     | 13/26 [00:04<00:04,  3.23it/s]\u001b[A\n",
            "Processing communities in parallel:  54%|█████▍    | 14/26 [00:04<00:03,  3.40it/s]\u001b[A\n",
            "Processing communities in parallel:  58%|█████▊    | 15/26 [00:05<00:03,  3.61it/s]\u001b[A\n",
            "Processing communities in parallel:  62%|██████▏   | 16/26 [00:05<00:02,  4.20it/s]\u001b[A\n",
            "Processing communities in parallel:  65%|██████▌   | 17/26 [00:05<00:01,  4.57it/s]\u001b[A\n",
            "Processing communities in parallel:  69%|██████▉   | 18/26 [00:05<00:01,  4.58it/s]\u001b[A\n",
            "Processing communities in parallel:  73%|███████▎  | 19/26 [00:06<00:02,  3.05it/s]\u001b[A\n",
            "Processing communities in parallel:  77%|███████▋  | 20/26 [00:06<00:01,  3.20it/s]\u001b[A\n",
            "Processing communities in parallel:  85%|████████▍ | 22/26 [00:06<00:00,  4.19it/s]\u001b[A\n",
            "Processing communities in parallel:  88%|████████▊ | 23/26 [00:07<00:00,  4.36it/s]\u001b[A\n",
            "Processing communities in parallel:  92%|█████████▏| 24/26 [00:07<00:00,  4.36it/s]\u001b[A\n",
            "Processing communities in parallel: 100%|██████████| 26/26 [00:08<00:00,  3.23it/s]\n",
            "Running retrievers for example_questions:   5%|▍         | 4/81 [07:37<2:28:58, 116.08s/it]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Running question:** List all topics."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **The Neural Maze**  \n",
            "- **Dr. Geetha Manjunath**  \n",
            "- **Research, summarization, and decision-making**  \n",
            "- **Visualizations from natural language queries**  \n",
            "- **Write-Select-Compress-Isolate framework**\n",
            "<module 'cypher' from '/content/Agentic_KAG/cypher.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "k2xXKhTtP-M7",
        "outputId": "b5479791-afce-451c-a05e-fbd7e6ba4a76"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2591398107.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JYUOexXaVoaw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}