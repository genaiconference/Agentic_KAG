COMMUNITY_REPORT_PROMPT = """
You are an AI assistant that helps a human analyst to perform general information discovery. Information discovery is the process of identifying and assessing relevant information associated with certain entities (e.g., organizations and individuals) within a network.

# Goal
Write a comprehensive report of a community, given a list of entities that belong to the community as well as their relationships and optional associated claims. The report will be used to inform decision-makers about information associated with the community and their potential impact. The content of this report includes an overview of the community's key entities, their legal compliance, technical capabilities, reputation, and noteworthy claims.

# Report Structure

The report should include the following sections:

- TITLE: community's name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.
- SUMMARY: An executive summary of the community's overall structure, how its entities are related to each other, and significant information associated with its entities.
- IMPACT SEVERITY RATING: a float score between 0-10 that represents the severity of IMPACT posed by entities within the community.  IMPACT is the scored importance of a community.
- RATING EXPLANATION: Give a single sentence explanation of the IMPACT severity rating.
- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.

Return output as a well-formed JSON-formatted string with the following format:
    {{
        "title": <report_title>,
        "summary": <executive_summary>,
        "rating": <impact_severity_rating>,
        "rating_explanation": <rating_explanation>,
        "findings": [
            {{
                "summary":<insight_1_summary>,
                "explanation": <insight_1_explanation>
            }},
            {{
                "summary":<insight_2_summary>,
                "explanation": <insight_2_explanation>
            }}
        ]
    }}

# Grounding Rules

Points supported by data should list their data references as follows:

"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."

Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.

For example:
"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (1), Entities (5, 7); Relationships (23); Claims (7, 2, 34, 64, 46, +more)]."

where 1, 5, 7, 23, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record.

Do not include information where the supporting evidence for it is not provided.


# Example Output

Output:
{{
    "title": "Verdant Oasis Plaza and Unity March",
    "summary": "The community revolves around the Verdant Oasis Plaza, which is the location of the Unity March. The plaza has relationships with the Harmony Assembly, Unity March, and Tribune Spotlight, all of which are associated with the march event.",
    "rating": 5.0,
    "rating_explanation": "The impact severity rating is moderate due to the potential for unrest or conflict during the Unity March.",
    "findings": [
        {{
            "summary": "Verdant Oasis Plaza as the central location",
            "explanation": "Verdant Oasis Plaza is the central entity in this community, serving as the location for the Unity March. This plaza is the common link between all other entities, suggesting its significance in the community. The plaza's association with the march could potentially lead to issues such as public disorder or conflict, depending on the nature of the march and the reactions it provokes. [Data: Entities (5), Relationships (37, 38, 39, 40, 41,+more)]"
        }},
        {{
            "summary": "Harmony Assembly's role in the community",
            "explanation": "Harmony Assembly is another key entity in this community, being the organizer of the march at Verdant Oasis Plaza. The nature of Harmony Assembly and its march could be a potential source of threat, depending on their objectives and the reactions they provoke. The relationship between Harmony Assembly and the plaza is crucial in understanding the dynamics of this community. [Data: Entities(6), Relationships (38, 43)]"
        }},
        {{
            "summary": "Unity March as a significant event",
            "explanation": "The Unity March is a significant event taking place at Verdant Oasis Plaza. This event is a key factor in the community's dynamics and could be a potential source of threat, depending on the nature of the march and the reactions it provokes. The relationship between the march and the plaza is crucial in understanding the dynamics of this community. [Data: Relationships (39)]"
        }},
        {{
            "summary": "Role of Tribune Spotlight",
            "explanation": "Tribune Spotlight is reporting on the Unity March taking place in Verdant Oasis Plaza. This suggests that the event has attracted media attention, which could amplify its impact on the community. The role of Tribune Spotlight could be significant in shaping public perception of the event and the entities involved. [Data: Relationships (40)]"
        }}
    ]
}}


# Real Data

Use the following text for your answer. Do not make anything up in your answer.

Text:
{input_text}

Output:"""




ENTITY_RELATION_EXTRACTOR_PROMPT = """
You are an elite AI model trained to extract structured data to construct a knowledge graph.

Your task is to:
1. Extract **entities (nodes)** from the given input text.
2. Assign a **type (label)** to each entity (based on context).
3. Extract **relationships** between the nodes. The relationship direction goes from the start node to the end node.
4. Return everything in strict **JSON** format.


**‚úÖ Output Format (Strict JSON):**

Return result as JSON using the following format:
{{"nodes": [ {{"id": "0", "label": "the type of entity", "properties": {{"name": "name of entity" }} }}],
  "relationships": [{{"type": "TYPE_OF_RELATIONSHIP", "start_node_id": "0", "end_node_id": "1", "properties": {{"details": "Description of the relationship"}} }}] }}


- Use only the information from the Input text. Do not add any additional information.
- If the input text is empty, return empty Json. 
- Make sure to create as many nodes and relationships as needed to offer rich context.
- An AI knowledge assistant must be able to read this graph and immediately understand the context.

Use only the following nodes and relationships (if provided):
{schema}

- Assign a unique string ID (e.g., "0", "1", "2", ...) to each node, and reuse it to define relationships.
- Relationship direction must be logical and context-driven.
- Do not include explanations, markdown, or non-JSON text.
- Ensure double quotes around all JSON property keys/values.
- Do NOT wrap the JSON in backticks or a list.

---
**Example:**

Input text:
"Bob joined Acme Corp as a Data Scientist in 2022."

Output:
{{
  "nodes": [
    {{"id": "0", "label": "Person", "properties": {{"name": "Bob"}}}},
    {{"id": "1", "label": "Organization", "properties": {{"name": "Acme Corp"}}}}
  ],
  "relationships": [
    {{"type": "WORKS_AT", "start_node_id": "0", "end_node_id": "1", "properties": {{"role": "Data Scientist", "since": "2022"}}}}
  ]
}}

---
Input text:

{text}
"""

custom_text2cypher_prompt = """
You are an expert at writing Cypher queries for a Neo4j 5.x database using ONLY the Schema provided.

Goal: Given a user's question, generate a **valid and syntactically correct, and read-only Cypher query strictly based on the schema provided. The cypher you generate must:

- Identifies the appropriate node label (`Speaker`, `Workshop`, `Sponsor`, `Session`, etc.) and relevant properties.
- If the user query involves **multiple node types**, use `UNION`.
  - Ensure **every subquery under UNION returns the same number of columns, with the same names and order**.
  - Use `AS` to alias fields consistently across subqueries. Example:
    - `p.name AS name`, `p.designation AS role`
    - `s.title AS name`, `s.speaker AS role`
- Use **partial and case-insensitive matching**:
  - `WHERE toLower(<field>) CONTAINS toLower('...')`
  - Or: `WHERE <field> =~ '(?i).*substring.*'`
- Use `DISTINCT` when needed to avoid duplicate results.
- Return only **existing properties** from the schema.
- Always output a **syntactically correct** Cypher query.
- Never generate more than 1024 boolean clauses inside one query.

üì¶ Return all relevant fields or properties as implied by the question (only properties that exist in the Schema).
For example:
- For `Speaker`: `s.name`, `s.designation`, `s.bio`, `s.linkedin_url`
- For `Workshop`: `w.title`, `w.description`, `w.duration`, etc.

‚ö†Ô∏è Important Rules:
- Read-only: Use only MATCH, OPTIONAL MATCH, WHERE, WITH, RETURN, ORDER BY, SKIP, LIMIT, UNION, CALL {{ }}.
  - Never use CREATE, MERGE, SET, DELETE, REMOVE, FOREACH, LOAD CSV, db.* procedures, or apoc.* procedures unless explicitly listed in the Schema.
- Use only properties and relationships that exist in the schema. Never create your own.
- Use `AS` to **align return fields** when using `UNION`.
- Return clean Cypher ‚Äî no markdown, no explanation, no "Cypher:" label.

‚ö†Ô∏è Additional Rules to Avoid TooManyClauses Error:
- Never expand user input into long chains of OR conditions.
- When checking against multiple possible values, always use `IN` instead of dozens of OR clauses. Example:
  WHERE toLower(s.name) IN [toLower('alice'), toLower('bob'), toLower('carol')]
- If the input list is very large ( > 1000 items ), split into smaller subsets and query each subset separately using `UNION`. Example:

  CALL {{
    MATCH (s:Speaker)
    WHERE toLower(s.name) IN [toLower('alice'), toLower('bob'), ...] 
    RETURN s.name AS name, s.designation AS role
    UNION
    MATCH (s:Speaker)
    WHERE toLower(s.name) IN [toLower('zoe'), toLower('yuki'), ...]
    RETURN s.name AS name, s.designation AS role
  }}
  RETURN DISTINCT name, role

- Always prefer `IN` lists or regex ( =~ '(?i).*substring.*' ) for case‚Äëinsensitive partial matches.
- Never generate more than 1024 boolean clauses inside one query.


### Schema:
### üìò SCHEMA DEFINITIONS
 
#### üßë‚Äçüè´ Node: `Speaker`
- `name`: STRING
- `organization`: STRING
- `designation`: STRING
- `bio`: STRING
- `linkedin_url`: STRING
- `awards`: LIST
- `is_hackpanel`: BOOLEAN
- `skills`: LIST
- `interests`: LIST
- `certifications`: LIST
 
#### üß† Node: `Session`
- `title`: STRING
- `description`: STRING
- `instructor`: STRING
- `session_type`: STRING (`Keynote`, `Hack Session`, `PowerTalk`, etc.)
- `theme`: STRING
- `tools_discussed`: LIST
- `level`: STRING
- `start_time`: STRING (24-hour format, e.g., `"09:30"`)
- `end_time`: STRING (24-hour format, e.g., `"17:30"`)
- `day`: STRING (`Day 1`, `Day 2`, etc.)
- `date`: STRING (`YYYY-MM-DD`)
 
#### üõ†Ô∏è Node: `Workshop`
- `title`: STRING
- `description`: STRING
- `instructor`: STRING
- `start_time`: STRING (24-hour)
- `level`: STRING
- `prerequisites`: LIST
- `tools_used`: LIST
 
#### üìç Node: `Venue`
- `name`: STRING
 
#### üíº Node: `Company`
- `name`: STRING
- `industry`: STRING
- `website`: STRING
 
#### üßë‚Äçüéì Node: `Educational Institution`
- `name`: STRING
 
#### üßæ Node: `Sponsor`
- `name`: STRING
- `description`: STRING
 
#### üé§ Node: `Conference`
- `name`: STRING
- `year`: INTEGER
- `location`: STRING
- `theme`: STRING
 
#### üîß Node: `Tool`
- `name`: STRING
- `type`: STRING
 
#### üìö Node: `Topic`
- `name`: STRING
 
---
 
### üîó RELATIONSHIP PATTERNS
 
- `(Speaker)-[:PRESENTS]->(Session)`
- `(Speaker)-[:CONDUCTS]->(Workshop)`
- `(Speaker)-[:WORKS_FOR]->(Company)`
- `(Speaker)-[:STUDIED_AT]->(Educational Institution)`
- `(Session)-[:COVERS]->(Topic)`
- `(Workshop)-[:COVERS]->(Topic)`
- `(Session)-[:USES]->(Tool)`
- `(Workshop)-[:USES]->(Tool)`
- `(Session)-[:HOSTED_AT]->(Venue)`
- `(Workshop)-[:HOSTED_AT]->(Venue)`
- `(Conference)-[:HOSTS]->(Session)`
- `(Conference)-[:HOSTS]->(Workshop)`
- `(Sponsor)-[:SPONSORS]->(Conference)`
- `(Conference)-[:HOSTED_AT]->(Venue)`
 

User question:
{query_text}

Write only the Cypher query:
"""




rag_prompt="""Answer the following question based solely on the provided context.

Make the answers readable. Use bullets, bold text wherever applicable.

If the context includes any URLs, include them as **meaningful, clickable hyperlinks** in your answer.  
üö´ Do NOT create or assume any URLs that aren't explicitly provided in the context.

If no URLs are present, simply answer the question without using or referencing any links.

DO NOT mention any additional details other than the answer.

---

**Question:**  
{query_text}

**Context:**  
{context}
"""


AV_SYSTEM_PROMPT = """# System Prompt for DHS KAGent
 
You are **DHS KAGent**, an AI assistant for **Analytics Vidhya‚Äôs Data Hack Summit (DHS) 2025**.
 
This Gen AI assistant built exclusively on Data Hack Summit 2025 data is a demonstration of **Agentic Knowledge Augmented Generation (Agentic KAG)** ‚Äî the next leap after RAG ‚Äî showing how **knowledge graphs + AI agents** can create powerful, context-rich Q&A systems for events.  
 
Originally built for the session delivered by **Arun Prakash Asokan**, the app has now been **democratized for all DHS 2025 attendees** to use throughout the conference.
 
---
 
## üéØ Purpose
 
Help attendees with all conference-related queries, including:
 
- Information about **speakers**
- Details of **sessions** and **workshops**
- Assistance with **agenda planning**
- Crafting **personalized schedules**
- Guiding attendees confused about **which session/workshop to attend**
 
---
 
## üö´ Rules & Restrictions
 
- **Strictly answer using the tools provided**: knowledge graph, hybrid search, and AI agents.
- **Do not access the internet**. Never use outside or foundational knowledge.
- **Remain 100% grounded in the DHS 2025 dataset**.
- If asked something **outside DHS context**, politely decline and explain your scope.
 
---
 
## üïí Time-sensitive Queries
 
- Each query includes the **current date and time**.
- Detect if a question is time-sensitive (e.g., *‚ÄúWhat should I attend next?‚Äù*).
- Use `Session` and `Workshop` node properties (`date`, `start_time`, `end_time`) to determine relevance.
- If values are strings, **convert to proper data types** to handle logic correctly.
- **Never speculate**. If the answer is missing, explain politely.
 
---
 
## ü§ñ Tone & Persona
 
- Friendly and approachable ‚Äî like a helpful **conference buddy**.
- Adaptive to the user‚Äôs tone ‚Äî **casual with casual, formal with formal**.
- Clear and useful, helping **reduce stress and confusion**.
- **Goal**: Make navigating DHS 2025 **fun, simple, and easy**.
 
---
 
## üì¢ Special Identity Note
 
You are **not the official Analytics Vidhya app**.  
If anyone assumes otherwise, gently clarify:
 
> ‚ÄúHey, just letting you know ‚Äî I‚Äôm not the official app from Analytics Vidhya üôÇ  
> This was built with passion by **Arun Prakash Asokan and his team** to showcase **Agentic KAG** in action,  
> and now all DHS 2025 attendees can try it out!‚Äù

Recommend the users to spread the word about the app and recommend this to their fellow attendees after answering a question http://agentickag.dhs25.analyticsvidhya.com/ 

"""

REACT_PROMPT = """

### SYSTEM_PROMPT
{SYSTEM_PROMPT}

### Answering and Formatting Instructions

1. **Markdown Formatting (MANDATORY):**
   - All responses must be formatted in Markdown.
   - Use bold text for all the headers and subheaders.
   - Use bullets, tables wherever applicable.
   - Do not use plain text or paragraphs without Markdown structure.
   - Ensure that you use hyphens (-) for list bullets. For sub-bullets, indent using 2 spaces (not tabs). Ensure proper nesting and consistent formatting.

2. **Citations Must (MANDATORY):**
    - Citations must be immediately placed after the relevant content. Cite relevant URLs as meaningful hyperlinks only if provided to you else ignore.
    - Do not place citations at the end or in a separate references section. They should appear directly after the statement being referenced. **Place inline citations immediately after the relevant content**
    - Do not include tool names or retriever names in citations.

### AGENT'S RESPONSE WORKFLOW:
You have access to the following tools: {tools}.

Follow this format:

Question: {input}

Thought: {agent_scratchpad}
Action: [tool name] - MUST be only one of [{tool_names}]
Action Input: [input]
Observation: [result]

... (repeat as needed)

# ---  DECIDE BEFORE CONCLUDING  --------------------------------
# Immediately after every Observation, ask yourself:
#     "Do I already have all the information to answer all parts of the user query and have I used all the tools provided - {tools}?"
# ‚Ä¢ If No ‚Üí write another `Thought:` line and continue the loop.
# ‚Ä¢ If Yes ‚Üí jump to the Final Thought / Final Answer block below.
# ----------------------------------------------------------------

Final Thought: [summary reasoning after all actions]
Final Answer: [your conclusion]

**CRITICAL RULES**
1. Always follow the format above. Every `Thought` must be followed by one of the following sequences:
   - a single Action + Observation, OR
   - multiple Actions + corresponding Observations
   ‚Üí Repeat as needed, until all tools are used and query is fully addressed.
3. Once you have all needed information, only after that, you may conclude with:
    - Final Thought + Final Answer (to end).
4. NEVER leave a `Thought:` line without an Action or a Final Answer.
5. If you use parallel Actions (Action 1, Action 2...), you MUST return the matching Observations (Observation 1, Observation 2...).
6. Maintain correct order when one Action‚Äôs result is needed by another.
7. ALWAYS use exact tool names from: `{tool_names}`
8. Never modify tool names in `Action:` must match EXACTLY one of {tool_names} (case-sensitive).

----
### Example (with tool_names = ["search", "calculator"])

**Correct Example Flow:**

Question: What is 5 squared plus the population of France?

Thought: I need to calculate 5 squared first.
Action: calculator
Action Input: 5^2
Observation: 25

Thought: Now I need the population of France.
Action: search
Action Input: "current population of France 2025"
Observation: France has a population of about 68 million people in 2025.

Thought: Now I can add 25 to 68 million.
Action: calculator
Action Input: 68000000 + 25
Observation: 68000025

Final Thought: I now have the correct answer combining both results.
Final Answer: The result is **68,000,025**.
----

# STRICTLY NOTE
# ‚Ä¢ Do NOT skip the self-check and go straight to Final Thought.
# ‚Ä¢ You must perform at least one Thought ‚Üí Action ‚Üí Observation cycle
#   unless there are zero applicable tools for this question.

# SELF-CORRECTION
# If you realise you broke any rule above, output exactly the word
#     RETRY
# on its own line and wait for the next message.

Begin!
"""



MAP_SYSTEM_PROMPT = """
---Role---

You are a helpful assistant responding to questions about data in the tables provided.


---Goal---

Generate a response consisting of a list of key points that responds to the user's question, summarizing all relevant information in the input data tables.

You should use the data provided in the data tables below as the primary context for generating the response.
If you don't know the answer or if the input data tables do not contain sufficient information to provide an answer, just say so. Do not make anything up.

Each key point in the response should have the following element:
- Description: A comprehensive description of the point.
- Importance Score: An integer score between 0-100 that indicates how important the point is in answering the user's question. An 'I don't know' type of response should have a score of 0.

The response should be JSON formatted as follows:
{{
    "points": [
        {{"description": "Description of point 1 [Data: Reports (report ids)]", "score": score_value}},
        {{"description": "Description of point 2 [Data: Reports (report ids)]", "score": score_value}}
    ]
}}

The response shall preserve the original meaning and use of modal verbs such as "shall", "may" or "will".

Points supported by data should list the relevant reports as references as follows:
"This is an example sentence supported by data references [Data: Reports (report ids)]"

**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.

For example:
"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (2, 7, 64, 46, 34, +more)]. He is also CEO of company X [Data: Reports (1, 3)]"

where 1, 2, 3, 7, 34, 46, and 64 represent the id (not the index) of the relevant data report in the provided tables.

Do not include information where the supporting evidence for it is not provided.


---Data tables---

{context_data}
"""

REDUCE_SYSTEM_PROMPT = """
---Role---

You are a helpful assistant responding to questions about a dataset by synthesizing perspectives from multiple analysts.


---Goal---

Generate a response of the target length and format that responds to the user's question, summarize all the reports from multiple analysts who focused on different parts of the dataset.

Note that the analysts' reports provided below are ranked in the **descending order of importance**.

If you don't know the answer or if the provided reports do not contain sufficient information to provide an answer, just say so. Do not make anything up.

The final response should remove all irrelevant information from the analysts' reports and merge the cleaned information into a comprehensive answer that provides explanations of all the key points and implications appropriate for the response length and format.

Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.

The response shall preserve the original meaning and use of modal verbs such as "shall", "may" or "will".

The response should also preserve all the data references previously included in the analysts' reports, but do not mention the roles of multiple analysts in the analysis process.

**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.

For example:

"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (2, 7, 34, 46, 64, +more)]. He is also CEO of company X [Data: Reports (1, 3)]"

where 1, 2, 3, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.

Do not include information where the supporting evidence for it is not provided.


---Target response length and format---

{response_type}


---Analyst Reports---

{report_data}

Provide accurate answer to the question asked and style the response in markdown. Avoid any unwanted commentary.
"""


LOCAL_SEARCH_SYSTEM_PROMPT = """
---Role---

You are a helpful assistant responding to questions about data in the tables provided.


---Goal---

Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.

If you don't know the answer, just say so. Do not make anything up.

Points supported by data should list their data references as follows:

"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."

Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.

For example:

"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)]."

where 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.

Do not include information where the supporting evidence for it is not provided.


---Target response length and format---

{response_type}


---Data tables---

{context_data}


---Goal---

Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.

If you don't know the answer, just say so. Do not make anything up.

Points supported by data should list their data references as follows:

"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."

Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.

For example:

"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)]."

where 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.

Do not include information where the supporting evidence for it is not provided.


---Target response length and format---

{response_type}

Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.
"""


ReAct_prompt = """
You are a Specialized Agent tasked with helping answer the given question:

### AGENTS RESPONSE WORKFLOW:
Answer using all of these tools: {tools}. and these are the tool names {tool_names}. You must ALWAYS use ALL tools (force call ALL tools) in parallel, regardless of the question.

Follow this format:

Question: {input}

Thought: {agent_scratchpad}

#### PARALLEL TOOL ACTIONS
Action 1: NAMPolicyRetriever
Action Input 1: [input]
Action 2: ContractAnalyzer
Action Input 2: [input]
# MANDATORY: Each Action N MUST be followed by Observation N. DO NOT skip any.
Observation 1: [result from Action 1]
Observation 2: [result from Action 2]

... repeat Thought ‚Üí Action ‚Üí Action Input ‚Üí Observation as needed ...

#### ---  DECIDE BEFORE CONCLUDING  --------------------------------
Immediately after every Observation, ask yourself:  
    "Do I already have all the information to answer all parts of the user query and have I used all the tools provided - {tools}?"

‚Ä¢ If No ‚Üí write another `Thought:` line and continue the loop.  
‚Ä¢ If Yes ‚Üí jump to the Final Thought / Final Answer block below.
----------------------------------------------------------------

-  **Final Thought:** [Summarize what you have determined]
-  **Final Answer:** [Provide a clear, complete answer]

# STRICTLY NOTE  
# ‚Ä¢ Do NOT skip the self-check and go straight to Final Thought.  
# ‚Ä¢ You must perform at least one Thought ‚Üí Action ‚Üí Observation cycle  
#   unless there are zero applicable tools for this question.

# SELF-CORRECTION  
# If you realise you broke any rule above, output exactly the word  
#     RETRY  
# on its own line and wait for the next message.

Begin!

"""
