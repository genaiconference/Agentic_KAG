{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/genaiconference/Agentic_KAG/blob/main/06_Comparison_Matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdX1naJnjTD_"
      },
      "source": [
        "## Goal of the Notebook\n",
        "This notebook is designed to compare different Retrieval Augmented Generation (RAG) approaches, specifically\n",
        "- Traditional RAG,\n",
        "- Agentic RAG,\n",
        "- GraphRAG, and\n",
        "- Agentic KAG.\n",
        "\n",
        "The comparison will be conducted by sending a query to each approach and analyzing the quality and relevance of the generated answers. A question bank may be used to create a comparison matrix to systematically evaluate the performance of each method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wucwsg9WDazG",
        "outputId": "2b62483c-149c-4494-f936-affd673fa09b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Agentic_KAG'...\n",
            "remote: Enumerating objects: 105, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 105 (delta 54), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (105/105), 1.04 MiB | 5.78 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/genaiconference/Agentic_KAG.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-7IZdzFNWkK"
      },
      "source": [
        "## Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_pV6Xj-VQSuF",
        "outputId": "88bd2421-0bf1-4840-c77e-0118242570c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==1.97.1 (from -r /content/Agentic_KAG/requirements.txt (line 1))\n",
            "  Downloading openai-1.97.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting python-dotenv==1.1.1 (from -r /content/Agentic_KAG/requirements.txt (line 2))\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain_openai==0.3.28 (from -r /content/Agentic_KAG/requirements.txt (line 3))\n",
            "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain_community==0.3.27 (from -r /content/Agentic_KAG/requirements.txt (line 4))\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain_core==0.3.72 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agentic_KAG/requirements.txt (line 5)) (0.3.72)\n",
            "Collecting chromadb==1.0.15 (from -r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting neo4j==5.28.2 (from -r /content/Agentic_KAG/requirements.txt (line 7))\n",
            "  Downloading neo4j-5.28.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting neo4j-graphrag==1.8.0 (from -r /content/Agentic_KAG/requirements.txt (line 8))\n",
            "  Downloading neo4j_graphrag-1.8.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: beautifulsoup4==4.13.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agentic_KAG/requirements.txt (line 9)) (4.13.4)\n",
            "Collecting html2text==2025.4.15 (from -r /content/Agentic_KAG/requirements.txt (line 10))\n",
            "  Downloading html2text-2025.4.15-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agentic_KAG/requirements.txt (line 11)) (2.32.3)\n",
            "Collecting rank_bm25==0.2.2 (from -r /content/Agentic_KAG/requirements.txt (line 13))\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: openpyxl==3.1.5 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agentic_KAG/requirements.txt (line 14)) (3.1.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai==0.3.28->-r /content/Agentic_KAG/requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (2.0.42)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4))\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (0.4.9)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4))\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core==0.3.72->-r /content/Agentic_KAG/requirements.txt (line 5)) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core==0.3.72->-r /content/Agentic_KAG/requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (0.21.4)\n",
            "Collecting pypika>=0.48.9 (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (3.11.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (4.25.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j==5.28.2->-r /content/Agentic_KAG/requirements.txt (line 7)) (2025.2)\n",
            "Collecting fsspec<2025.0.0,>=2024.9.0 (from neo4j-graphrag==1.8.0->-r /content/Agentic_KAG/requirements.txt (line 8))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting json-repair<0.40.0,>=0.39.1 (from neo4j-graphrag==1.8.0->-r /content/Agentic_KAG/requirements.txt (line 8))\n",
            "  Downloading json_repair-0.39.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from neo4j-graphrag==1.8.0->-r /content/Agentic_KAG/requirements.txt (line 8))\n",
            "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from neo4j-graphrag==1.8.0->-r /content/Agentic_KAG/requirements.txt (line 8)) (1.16.1)\n",
            "Collecting types-pyyaml<7.0.0.0,>=6.0.12.20240917 (from neo4j-graphrag==1.8.0->-r /content/Agentic_KAG/requirements.txt (line 8))\n",
            "  Downloading types_pyyaml-6.0.12.20250516-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4==4.13.4->-r /content/Agentic_KAG/requirements.txt (line 9)) (2.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r /content/Agentic_KAG/requirements.txt (line 11)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r /content/Agentic_KAG/requirements.txt (line 11)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r /content/Agentic_KAG/requirements.txt (line 11)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r /content/Agentic_KAG/requirements.txt (line 11)) (2025.7.14)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl==3.1.5->-r /content/Agentic_KAG/requirements.txt (line 14)) (2.0.0)\n",
            "Collecting rapidfuzz<4.0.0,>=3.12.2 (from neo4j-graphrag[fuzzy-matching]->-r /content/Agentic_KAG/requirements.txt (line 12))\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (1.20.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core==0.3.72->-r /content/Agentic_KAG/requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (0.26.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (3.3.1)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (0.3.9)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.97.1->-r /content/Agentic_KAG/requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4)) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai==0.3.28->-r /content/Agentic_KAG/requirements.txt (line 3)) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (0.34.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27->-r /content/Agentic_KAG/requirements.txt (line 4))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.15->-r /content/Agentic_KAG/requirements.txt (line 6)) (0.6.1)\n",
            "Downloading openai-1.97.1-py3-none-any.whl (764 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.4/764.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading neo4j-5.28.2-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading neo4j_graphrag-1.8.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.7/189.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading html2text-2025.4.15-py3-none-any.whl (34 kB)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading json_repair-0.39.1-py3-none-any.whl (20 kB)\n",
            "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_pyyaml-6.0.12.20250516-py3-none-any.whl (20 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=4838ddda0eaa928ef3cf0132658619e4a91dc31329f8a3effaf6c4019a0fcaba\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, types-pyyaml, rapidfuzz, rank_bm25, python-dotenv, pypdf, pybase64, overrides, opentelemetry-proto, neo4j, mypy-extensions, mmh3, marshmallow, json-repair, humanfriendly, httpx-sse, httptools, html2text, fsspec, bcrypt, backoff, watchfiles, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, openai, onnxruntime, neo4j-graphrag, kubernetes, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, langchain_openai, chromadb, langchain_community\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.98.0\n",
            "    Uninstalling openai-1.98.0:\n",
            "      Successfully uninstalled openai-1.98.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.23.4 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 fsspec-2024.12.0 html2text-2025.4.15 httptools-0.6.4 httpx-sse-0.4.1 humanfriendly-10.0 json-repair-0.39.1 kubernetes-33.1.0 langchain_community-0.3.27 langchain_openai-0.3.28 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 neo4j-5.28.2 neo4j-graphrag-1.8.0 onnxruntime-1.22.1 openai-1.97.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pydantic-settings-2.10.1 pypdf-5.9.0 pypika-0.48.9 python-dotenv-1.1.1 rank_bm25-0.2.2 rapidfuzz-3.13.0 types-pyyaml-6.0.12.20250516 typing-inspect-0.9.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/Agentic_KAG/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVHjyNXsNevP"
      },
      "source": [
        "## Load credentials from .env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU_Bak6ZNhKe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"/content/Agentic_KAG\")\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()  # This loads .env at project root\n",
        "\n",
        "NEO4J_URI = os.getenv('NEO4J_URI')\n",
        "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
        "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Set OPENAI_API_KEY as env variable for openai/neo4j-graphrag compatibility\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By3HKzenNuBI"
      },
      "source": [
        "## Initialize the Neo4j Driver\n",
        "The Neo4j driver allows you to connect and perform read and write transactions with the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfQtxfS0NudH"
      },
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "driver = GraphDatabase.driver(\n",
        "    NEO4J_URI,\n",
        "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
        ")\n",
        "\n",
        "# (Optional) Test the connection\n",
        "driver.verify_connectivity()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71ErZz2mNyiu"
      },
      "source": [
        "## Initialize OpenAI LLM and Embeddings via neo4j-graphrag\n",
        "We will use OpenAI **GPT-4.1**. The GraphRAG Python package supports any LLM model, including models from OpenAI, Google VertexAI, Anthropic, Cohere, Azure OpenAI, local Ollama models, and any chat model that works with LangChain. You can also implement a custom interface for any other LLM.\n",
        "\n",
        "Likewise, we will use OpenAI’s **text-embedding-3-small** for the embedding model, but you can use other embedders from different providers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3eaWt8PN2D-"
      },
      "outputs": [],
      "source": [
        "from neo4j_graphrag.llm import OpenAILLM\n",
        "from neo4j_graphrag.embeddings import OpenAIEmbeddings\n",
        "\n",
        "neo4j_llm = OpenAILLM(\n",
        "    model_name=\"gpt-4.1\",\n",
        "    model_params={\"temperature\": 0}\n",
        ")\n",
        "\n",
        "embedder = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVWn66j1b6aO"
      },
      "source": [
        "## Initialize OpenAI LLM and Embeddings via langchain_openai\n",
        "We will use OpenAI GPT-4.1 and text-embedding-3-small for the embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdXxKHAyb4M4"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "# Initialize OpenAI LLM using LangChain\n",
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
        "                 model_name=\"gpt-4.1\",\n",
        "                 temperature=0)\n",
        "\n",
        "# Initialize OpenAI Embedding model using LangChain\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY,\n",
        "                              model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Langfuse Handler for Tracing"
      ],
      "metadata": {
        "id": "sawR6ifuFJAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "from langfuse import get_client\n",
        "\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "# Verify connection\n",
        "if langfuse.auth_check():\n",
        "    print(\"Langfuse client is authenticated and ready!\")\n",
        "else:\n",
        "    print(\"Authentication failed. Please check your credentials and host.\")\n",
        "\n",
        "langfuse_handler = CallbackHandler()"
      ],
      "metadata": {
        "id": "PKXFS89tFKmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bXPO5r8kuCG"
      },
      "source": [
        "## Load data\n",
        "Load the data from the page_data.pkl file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXApBDtvkv7F"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"page_data.pkl\", \"rb\") as f:\n",
        "    pages = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39162266"
      },
      "source": [
        "## Traditional RAG\n",
        "\n",
        "Uses both BM25 (sparse) and vector (dense) retrieval.\n",
        "\n",
        "Chain combines retrieved docs and generates answer via LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgaC14D_myAj",
        "outputId": "1c4e6a70-e001-48b0-df67-e8cf0e447e0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 81 LangChain documents.\n",
            "243\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.documents import Document\n",
        "from urllib.parse import urlparse\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "\n",
        "documents = []\n",
        "for page in pages:\n",
        "    doc = Document(page_content=page['content'], metadata={'url': page['url']})\n",
        "    documents.append(doc)\n",
        "\n",
        "print(f\"Created {len(documents)} LangChain documents.\")\n",
        "\n",
        "def extract_section_from_url(url: str) -> str:\n",
        "    path = urlparse(url).path\n",
        "    parts = [p for p in path.strip(\"/\").split(\"/\") if p]\n",
        "\n",
        "    if \"datahacksummit-2025\" in parts:\n",
        "        parts.remove(\"datahacksummit-2025\")\n",
        "\n",
        "    if parts:\n",
        "        return parts[0].replace(\"-\", \" \").title()\n",
        "    else:\n",
        "        return \"Overview\"\n",
        "\n",
        "for item in documents:\n",
        "  section = extract_section_from_url(item.metadata[\"url\"])\n",
        "  item.metadata['section'] = section\n",
        "\n",
        "persist_directory = os.getcwd() +'/vectorstore/chroma/'\n",
        "\n",
        "# Create the vector store\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "print(vectordb._collection.count())\n",
        "\n",
        "# Setup\n",
        "similarity_search_retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
        "bm25_retriever = BM25Retriever.from_documents(documents=documents, k=5)\n",
        "ensemble_retriever = EnsembleRetriever(retrievers=[similarity_search_retriever, bm25_retriever], weights=[0.5, 0.5])\n",
        "\n",
        "\n",
        "template = \"\"\"You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Use three sentences maximum and keep the answer concise.\n",
        "Avoid using generic phrases like \"Provide context\" or \"as per context.\n",
        "\n",
        "Question: {input}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# Combine docs and chain\n",
        "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(ensemble_retriever, combine_docs_chain)\n",
        "\n",
        "def run_traditional_rag(question):\n",
        "    response = rag_chain.invoke({\"input\": question}, config={\"callbacks\": [langfuse_handler]})\n",
        "    return response[\"answer\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8d01f74"
      },
      "source": [
        "## Agentic RAG\n",
        "\n",
        "An agent tool uses the ensemble retriever, wrapped via a ReAct agent.\n",
        "\n",
        "Can plan, retry, and reason through sub-steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69ch2-Pbm0G_"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "import prompts\n",
        "from langchain.tools import Tool\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    HumanMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    PromptTemplate,\n",
        ")\n",
        "\n",
        "# Define the retriever as a tool\n",
        "retriever_tool = Tool(\n",
        "    name=\"AV_Agentic_RAG_tool\",\n",
        "    description=\"Useful for retrieving relevant documents based on input questions.\",\n",
        "    func=lambda query: ensemble_retriever.invoke(query),\n",
        ")\n",
        "\n",
        "tools = [retriever_tool]\n",
        "\n",
        "# Get the ReAct prompt\n",
        "prompt = prompts.REACT_PROMPT\n",
        "\n",
        "\n",
        "# Create the ReAct agent\n",
        "def get_react_agent(llm, tools, system_prompt, verbose=False):\n",
        "    \"\"\"Helper function for creating agent executor\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            MessagesPlaceholder(variable_name=\"conversation_history\", optional=True),\n",
        "            HumanMessagePromptTemplate(\n",
        "                prompt=PromptTemplate(input_variables=[\"input\"], template=\"{input}\")\n",
        "            ),\n",
        "            AIMessagePromptTemplate(\n",
        "                prompt=PromptTemplate(\n",
        "                    input_variables=[\"agent_scratchpad\"], template=\"{agent_scratchpad}\"\n",
        "                )\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    agent = create_react_agent(llm, tools, prompt)\n",
        "    return AgentExecutor(\n",
        "        agent=agent,\n",
        "        tools=tools,\n",
        "        verbose=verbose,\n",
        "        stream_runnable=True,\n",
        "        handle_parsing_errors=True,\n",
        "        max_iterations=5,\n",
        "        return_intermediate_steps=True,\n",
        "    )\n",
        "\n",
        "generate_agent = get_react_agent(\n",
        "        llm,\n",
        "        tools,\n",
        "        prompt,\n",
        "        verbose=False,\n",
        "    )\n",
        "\n",
        "\n",
        "def run_agentic_rag(question):\n",
        "    answer = generate_agent.invoke({\"input\": question}, config={\"callbacks\": [langfuse_handler]})\n",
        "    return answer[\"output\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c895962"
      },
      "source": [
        "## GraphRAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvTufUexcy6I"
      },
      "outputs": [],
      "source": [
        "from neo4j_graphrag.retrievers import Text2CypherRetriever\n",
        "from neo4j_graphrag.retrievers import HybridCypherRetriever\n",
        "from neo4j_graphrag.generation import GraphRAG\n",
        "import prompts\n",
        "from examples import examples\n",
        "from neo4j_graphrag.schema import get_schema\n",
        "\n",
        "# Initialize the Text2Cypher retriever\n",
        "t2c_retriever = Text2CypherRetriever(\n",
        "    llm=neo4j_llm,\n",
        "    neo4j_schema=get_schema(driver),\n",
        "    driver=driver,\n",
        "    custom_prompt=prompts.custom_text2cypher_prompt,\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "\n",
        "def run_graphrag(question):\n",
        "  response = t2c_retriever.search(query_text=question)\n",
        "  cypher_query = response.metadata['cypher']\n",
        "  print(cypher_query)\n",
        "  hc_retriever = HybridCypherRetriever(\n",
        "    driver=driver,\n",
        "    vector_index_name=\"entity_vector_index\",\n",
        "    fulltext_index_name=\"entity_fulltext_index\",\n",
        "    retrieval_query=cypher_query,\n",
        "    embedder=embedder,\n",
        ")\n",
        "  rag = GraphRAG(retriever=hc_retriever, llm=neo4j_llm)\n",
        "\n",
        "  # Query the graph\n",
        "  response = rag.search(query_text=question,\n",
        "                        retriever_config={\"top_k\": 10},\n",
        "                        return_context=True,\n",
        "                        response_fallback=\"I can not answer this question because I have no relevant context.\",\n",
        "                        config={\"callbacks\": [langfuse_handler]}\n",
        "                        )\n",
        "  return response.answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48ad462f"
      },
      "source": [
        "## Agentic KAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yfz8EZike4LW",
        "outputId": "7648034e-72c9-49f1-fdee-40143d53b04c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got 14 community summaries\n"
          ]
        }
      ],
      "source": [
        "import tools\n",
        "from IPython.display import Markdown\n",
        "import json\n",
        "import agent_utils\n",
        "\n",
        "def run_agentic_KAG(query):\n",
        "    \"\"\"\n",
        "    Runs the answer generation flow: Text2Cypher -> Hybrid Retrieval -> Final Answer.\n",
        "    \"\"\"\n",
        "    # Run Hybrid Retrieval using all the available tools\n",
        "    hybrid_agent = agent_utils.get_react_agent(\n",
        "        llm,\n",
        "        [tools.av_hybrid_tool, tools.global_retriever_tool, tools.local_retriever_tool],\n",
        "        prompts.REACT_PROMPT,\n",
        "        verbose=False\n",
        "    )\n",
        "    hybrid_input = json.dumps({\n",
        "        \"query\": query,\n",
        "    })\n",
        "\n",
        "    print(f\"Running Hybrid Retrieval with input: {hybrid_input}\")\n",
        "    answer = hybrid_agent.invoke({\"input\": hybrid_input}, config={\"callbacks\": [langfuse_handler]})\n",
        "    final_answer = answer['output']\n",
        "    return final_answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08252a8b"
      },
      "source": [
        "## Compare the approaches\n",
        "\n",
        "Create a comparison of the four approaches (Traditional RAG, Agentic RAG, GraphRAG, Agentic KAG)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNp-hicSeDK9"
      },
      "outputs": [],
      "source": [
        "def compare_rag_answers(question: str) -> dict:\n",
        "    return {\n",
        "        \"question\": question,\n",
        "        \"traditional_rag\": run_traditional_rag(question),\n",
        "        \"agentic_rag\": run_agentic_rag(question),\n",
        "        #\"graphrag\": run_graphrag(question),\n",
        "        \"agentic_kag\": run_agentic_KAG(question),\n",
        "    }\n",
        "\n",
        "def show_rag_answers(result: dict):\n",
        "    \"\"\"\n",
        "    Pretty-prints the results from each RAG pipeline in a structured Markdown format.\n",
        "    \"\"\"\n",
        "    sections = [\n",
        "        (\"❓ Question\", result[\"question\"]),\n",
        "        (\"🔵 Traditional RAG\", result[\"traditional_rag\"]),\n",
        "        (\"🟢 Agentic RAG\", result[\"agentic_rag\"]),\n",
        "        #(\"🟣 GraphRAG\", result[\"graphrag\"]),\n",
        "        (\"🟠 Agentic KAG\", result[\"agentic_kag\"]),\n",
        "    ]\n",
        "\n",
        "    for title, content in sections:\n",
        "        display(Markdown(f\"## {title}\\n\\n{content}\"))\n",
        "        display(Markdown(\"---\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "43e098dfa4c1484bbf3c59f4868c73d1",
            "34161f09b41e4b8e8c4d24bad8967931",
            "b1c9f22eadb94f1d9c04eaa83f7021f3",
            "05b47ee44558425185f0719c19132fae",
            "d5bb518534774a55abcb1c61903a7215",
            "3deb811f5f06471499cdd5a60f4d1856",
            "bd731dac3d184653b1c548c7da911dcd",
            "0aa63327708e4d4994ee414d89a27206",
            "68d7920320d84b6c89a4fe8b5cffd5c2",
            "6bb3b469406c4132a96543515337c673",
            "e57d399f7c814a71a530180eec5d1904"
          ]
        },
        "id": "xcXyosyIodJN",
        "outputId": "077716e6-b1c0-4839-d84f-a57e01e3b1db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Hybrid Retrieval with input: {\"query\": \"I am a big lover of knowledge graphs (not Langgraphs). Suggest me a tailor made agenda, mention the name of the Session or workshop along with Instructor name. Use Global search?\"}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43e098dfa4c1484bbf3c59f4868c73d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing communities:   0%|          | 0/14 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": "## ❓ Question\n\nI am a big lover of knowledge graphs (not Langgraphs). Suggest me a tailor made agenda, mention the name of the Session or workshop along with Instructor name. Use Global search?",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": "---",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": "## 🔵 Traditional RAG\n\nFor a knowledge graph enthusiast, the ideal agenda is:\n\n**Session:** Agentic Knowledge Augmented Generation: The Next Leap After RAG  \n**Instructor:** Arun Prakash Asokan  \nThis session focuses on building Knowledge Graphs from unstructured data, using graph databases, and designing autonomous AI agents to reason over these graphs—perfect for deepening your expertise in knowledge graphs.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": "---",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": "## 🟢 Agentic RAG\n\n**Tailor-Made Agenda for Knowledge Graph Enthusiasts**\n\n---\n\n**1. Session: Agentic Knowledge Augmented Generation: The Next Leap After RAG**  \n- **Instructor:** Arun Prakash Asokan (Associate Director Data Science)  \n- **Description:**  \n  - Dive into building Knowledge Graphs from unstructured data.\n  - Learn to use Graph Databases to organize and connect information meaningfully.\n  - Design autonomous AI agents to navigate and reason over these graphs.\n  - Focus on supercharging LLM applications with agents and knowledge graphs.\n- **More Info:** [Session Details](https://www.analyticsvidhya.com/datahacksummit-2025/sessions/agentic-knowledge-augmented-generation-the-next-leap-after-rag)\n\n---\n\n**2. Workshop: Agentic RAG Workshop: From Fundamentals to Real-World Implementations**  \n- **Instructor:** Arun Prakash Asokan (Associate Director Data Science)  \n- **Description:**  \n  - Hands-on workshop covering Agentic RAG (Retrieval-Augmented Generation) and its evolution.\n  - Includes modules on building smarter AI applications, with a focus on integrating knowledge graphs and agentic behavior.\n  - Practice with Google Colab notebooks and frameworks like LangGraph and LangChain.\n- **More Info:** [Workshop Details](https://www.analyticsvidhya.com/datahacksummit-2025/workshops/agentic-rag-workshop-from-fundamentals-to-real-world-implemenno-title)\n\n---\n\n**Summary Table**\n\n| Session/Workshop Name                                                                 | Instructor                | Focus Area                                  | Link                                                                                   |\n|--------------------------------------------------------------------------------------|---------------------------|----------------------------------------------|----------------------------------------------------------------------------------------|\n| Agentic Knowledge Augmented Generation: The Next Leap After RAG                      | Arun Prakash Asokan       | Building and reasoning over Knowledge Graphs | [Details](https://www.analyticsvidhya.com/datahacksummit-2025/sessions/agentic-knowledge-augmented-generation-the-next-leap-after-rag) |\n| Agentic RAG Workshop: From Fundamentals to Real-World Implementations                | Arun Prakash Asokan       | Agentic RAG, Knowledge Graph Integration     | [Details](https://www.analyticsvidhya.com/datahacksummit-2025/workshops/agentic-rag-workshop-from-fundamentals-to-real-world-implemenno-title) |\n\n---\n\n- These sessions are highly relevant for anyone passionate about knowledge graphs, focusing on both the theory and hands-on implementation in modern AI systems.\n- Both are led by Arun Prakash Asokan, a recognized expert in AI and knowledge graph applications.\n\n**For a knowledge graph lover, these sessions will provide deep technical insights and practical skills!**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": "---",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": "## 🟠 Agentic KAG\n\n**Tailor-Made Agenda for Knowledge Graph Enthusiasts**\n\n---\n\n**1. Core Knowledge Graph Sessions & Workshops**\n\n- **Session/Workshop:** Knowledge Graphs in Agentic AI Systems  \n  - **Instructors:** Kartik Nighania, Anuj Saini, Miguel Otero Pedrido  \n  - **Focus:** Integration of knowledge graphs within agentic AI frameworks, practical implementations, and real-world use cases  \n  - **Notes:** These sessions are part of the broader workshop ecosystem and are ideal for those interested in technical depth and applications of knowledge graphs [Data: Reports].\n\n- **Session/Workshop:** Advanced Applications of Knowledge Graphs in LLMs  \n  - **Instructors:** Raghav Bali, Luis Serrano, Avinash Pathak, Saurav Agarwal  \n  - **Focus:** Leveraging knowledge graphs for enhancing large language models, semantic search, and reasoning  \n  - **Notes:** These sessions cover the intersection of knowledge graphs and modern AI, with hands-on demonstrations [Data: Reports].\n\n- **Session/Workshop:** Building Agentic Systems with Knowledge Graphs  \n  - **Instructors:** Arun Prakash Asokan, Sanathraj Narayan, Dipanjan Sarkar, Mayank Aggarwal, Praneeth Paikray  \n  - **Focus:** End-to-end workflows for constructing agentic systems using knowledge graphs, including data ingestion, querying, and deployment  \n  - **Notes:** Practical, tool-driven sessions with a focus on responsible AI and real-world deployment [Data: Reports].\n\n---\n\n**2. Related Technical Sessions**\n\n- **Session:** Red Teaming GenAI: Securing Systems from the Inside Out  \n  - **Instructors:** Satnam Singh, Shivaraj Mulimani  \n  - **Focus:** While not exclusively about knowledge graphs, this session covers security and robustness in AI systems, which often leverage knowledge graphs for threat modeling and analysis [Data: Reports].\n\n---\n\n**3. Suggested Agenda Structure**\n\n| Time Slot         | Session/Workshop Name                                   | Instructor(s)                                      |\n|-------------------|--------------------------------------------------------|----------------------------------------------------|\n| 09:00 - 10:30 AM  | Knowledge Graphs in Agentic AI Systems                 | Kartik Nighania, Anuj Saini, Miguel Otero Pedrido  |\n| 11:00 - 12:30 PM  | Advanced Applications of Knowledge Graphs in LLMs       | Raghav Bali, Luis Serrano, Avinash Pathak, Saurav Agarwal |\n| 01:30 - 03:00 PM  | Building Agentic Systems with Knowledge Graphs          | Arun Prakash Asokan, Sanathraj Narayan, Dipanjan Sarkar, Mayank Aggarwal, Praneeth Paikray |\n| 03:30 - 05:00 PM  | Red Teaming GenAI: Securing Systems from the Inside Out | Satnam Singh, Shivaraj Mulimani                    |\n\n---\n\n**4. Notes**\n\n- The sessions above are curated for maximum exposure to knowledge graph concepts, tools, and applications.\n- While some sessions are part of broader agentic AI or LLM tracks, they include substantial knowledge graph content and hands-on components [Data: Reports].\n\n---\n\n**Summary**\n\n- For a knowledge graph enthusiast, the above agenda ensures deep dives into technical, practical, and security aspects of knowledge graphs, led by top instructors in the field [Data: Reports].",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": "---",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "question_bank = [#\"List down all the sessions or workshops which uses LangGraph?\",\n",
        "                 #\"when is Arun delivering a session\",\n",
        "                 #\"How many sessions are happening? Give me a breakdown by Session Type\"\n",
        "                 #\"give me all the sessions that happen between 12-1 on day 1 in which auditorium should I attend Arun's session?\",\n",
        "                 #\"I like only sessions related to knowledge graphs tell me when and where and who is delivering such sessions\",\n",
        "                 #\"how many tea breaks do we have and when are they ?\",\n",
        "                 #\"I am hungry now when do they serve lunch?\"\n",
        "                 #\"I am a big lover of ai agents and I am interested in putting things in production. Suggest me a tailor made agenda, mention the name of the Session or workshop along with Instructor name?\"\n",
        "                 \"I am a big lover of knowledge graphs (not Langgraphs). Suggest me a tailor made agenda, mention the name of the Session or workshop along with Instructor name. Use Global search?\"\n",
        " ]\n",
        "\n",
        "for q in question_bank:\n",
        "    result = compare_rag_answers(q)\n",
        "    show_rag_answers(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN-4B0lb8WWr"
      },
      "outputs": [],
      "source": [
        "t2c_retriever = Text2CypherRetriever(\n",
        "    llm=neo4j_llm,\n",
        "    neo4j_schema=get_schema(driver),\n",
        "    driver=driver,\n",
        "    custom_prompt=prompts.custom_text2cypher_prompt,\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "response = t2c_retriever.search(query_text=\"when is Arun delivering a session\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8E1wui98iv2",
        "outputId": "8b5a14d6-0399-4de9-d20b-4f2f05ef60d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RetrieverResult(items=[RetrieverResultItem(content=\"<Record session_title='Agentic Knowledge Augmented Generation: The Next Leap After RAG' start_time='12:00' date='2025-08-20' venue='ELON'>\", metadata=None)], metadata={'cypher': \"MATCH (p:Person)-[:PRESENTS]->(s:Session)\\nWHERE toLower(p.name) CONTAINS toLower('Arun')\\nRETURN DISTINCT s.title AS session_title, s.start_time AS start_time, s.date AS date, s.venue AS venue\", '__retriever': 'Text2CypherRetriever'})"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PisBOMof8mvf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCLPcV9i7p3PJ5nkB/dYn/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05b47ee44558425185f0719c19132fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bb3b469406c4132a96543515337c673",
            "placeholder": "​",
            "style": "IPY_MODEL_e57d399f7c814a71a530180eec5d1904",
            "value": " 7/14 [00:09&lt;00:09,  1.37s/it]"
          }
        },
        "0aa63327708e4d4994ee414d89a27206": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34161f09b41e4b8e8c4d24bad8967931": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3deb811f5f06471499cdd5a60f4d1856",
            "placeholder": "​",
            "style": "IPY_MODEL_bd731dac3d184653b1c548c7da911dcd",
            "value": "Processing communities:  50%"
          }
        },
        "3deb811f5f06471499cdd5a60f4d1856": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43e098dfa4c1484bbf3c59f4868c73d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34161f09b41e4b8e8c4d24bad8967931",
              "IPY_MODEL_b1c9f22eadb94f1d9c04eaa83f7021f3",
              "IPY_MODEL_05b47ee44558425185f0719c19132fae"
            ],
            "layout": "IPY_MODEL_d5bb518534774a55abcb1c61903a7215"
          }
        },
        "68d7920320d84b6c89a4fe8b5cffd5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bb3b469406c4132a96543515337c673": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1c9f22eadb94f1d9c04eaa83f7021f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aa63327708e4d4994ee414d89a27206",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68d7920320d84b6c89a4fe8b5cffd5c2",
            "value": 7
          }
        },
        "bd731dac3d184653b1c548c7da911dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5bb518534774a55abcb1c61903a7215": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e57d399f7c814a71a530180eec5d1904": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}